{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9\n",
    "lamda = 0.9\n",
    "rewards = torch.as_tensor([1,1,1,1,12,1,1,1,1,1,2], dtype=torch.float32)\n",
    "dones = torch.as_tensor([0,0,0,0,1,0,0,0,0,0,1], dtype=torch.float32)\n",
    "values = torch.ones(11)\n",
    "successor_values = torch.ones(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_gae(rewards, values, successor_values, gamma, lamda):\n",
    "    N = len(rewards)\n",
    "    deltas = rewards + gamma * successor_values - values\n",
    "    gamlam = gamma * lamda\n",
    "    gamlam_geo_series = torch.as_tensor([gamlam**i\n",
    "                                         for i in range(N)]) * (1 - gamlam)\n",
    "    full_gamlam_matrix = torch.stack(\n",
    "        [torch.roll(gamlam_geo_series, shifts=n) for n in range(N)])\n",
    "    full_gamlam_matrix = torch.triu(full_gamlam_matrix)\n",
    "    # make sure it sums to one:\n",
    "    # (by making the term for the last value be 1 - sum(all other terms))\n",
    "    full_gamlam_matrix[:, -1] = 1 - full_gamlam_matrix[:, :-1].sum(axis=1)\n",
    "    return full_gamlam_matrix @ deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_dones = (is_terminals.nonzero()[:, 0] + 1).tolist()\n",
    "location_dones = [0] + location_dones + [-1]\n",
    "episodes_gaes = []\n",
    "for start, end in zip(location_dones[:-1], location_dones[1:]):\n",
    "    if end != -1:\n",
    "        episodes_gaes.append(\n",
    "            single_gae(rewards[start:end], values[start:end],\n",
    "                       successor_values[start:end], gamma, lamda))\n",
    "    else:\n",
    "        episodes_gaes.append(\n",
    "            single_gae(rewards[start:], values[start:],\n",
    "                       successor_values[start:], gamma, lamda))\n",
    "return torch.cat(episodes_gaes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_dones = dones.nonzero()[:,0]\n",
    "len_chunks = location_dones[1:] - location_dones[0]\n",
    "len_chunks = len_chunks.tolist() + [N - sum(len_chunks).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 5]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "start (5) + length (11) exceeds dimension size (11).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation_dones\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cv38/lib/python3.8/site-packages/torch/functional.py:156\u001b[0m, in \u001b[0;36msplit\u001b[0;34m(tensor, split_size_or_sections, dim)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    151\u001b[0m         split, (tensor,), tensor, split_size_or_sections, dim\u001b[38;5;241m=\u001b[39mdim)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Overwriting reason:\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# This dispatches to two ATen functions depending on the type of\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# split_size_or_sections. The branching code is in tensor.py, which we\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# call here.\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_size_or_sections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cv38/lib/python3.8/site-packages/torch/tensor.py:499\u001b[0m, in \u001b[0;36mTensor.split\u001b[0;34m(self, split_size, dim)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(Tensor, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39msplit_with_sizes(split_size, dim)\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_with_sizes\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: start (5) + length (11) exceeds dimension size (11)."
     ]
    }
   ],
   "source": [
    "torch.split(rewards, location_dones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  1.,  1.,  1., 12.,  1.,  1.,  1.,  1.,  1.,  2.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 5.6351,  6.7459,  8.1171,  9.8100, 11.9000]),\n",
       " tensor([1.2487, 1.3305, 1.4314, 1.5561, 1.7100, 1.9000])]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes_gaes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.6351,  6.7459,  8.1171,  9.8100, 11.9000,  1.2487,  1.3305,  1.4314,\n",
       "         1.5561,  1.7100,  1.9000])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  1.,  1.,  1., 12.,  1.,  1.,  1.,  1.,  1.,  2.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4],\n",
       "        [10]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gae(rewards, values, successor_values, dones, gamma, lamda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(rewards)\n",
    "deltas = rewards + gamma * successor_values * (1-dones) - values\n",
    "gamlam = gamma * lamda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamlam_geo_series = torch.as_tensor([gamlam**i\n",
    "                                     for i in range(N)]) * (1 - gamlam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.0900, 0.0810, 0.0729, 0.0656, 0.0590, 0.0531, 0.0478, 0.0430,\n",
       "        0.0387, 0.0349])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamlam_geo_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9000, 0.9000, 0.9000, 0.9000, 1.0000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
       "        0.9000, 1.0000])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 2.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successor_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv38",
   "language": "python",
   "name": "cv38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
