{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from einops.layers.torch import Rearrange\n",
    "from einops import rearrange\n",
    "\n",
    "from typing import Any, Dict, Tuple, Optional\n",
    "from game_mechanics import (\n",
    "    ChooseMoveCheckpoint,\n",
    "    ShooterEnv,\n",
    "    checkpoint_model,\n",
    "    choose_move_randomly,\n",
    "    human_player,\n",
    "    load_network,\n",
    "    play_shooter,\n",
    "    save_network,\n",
    ")\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "\n",
    "from utils import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEAM_NAME = \"Hristo\"  # <---- Enter your team name here!\n",
    "assert TEAM_NAME != \"Team Name\", \"Please change your TEAM_NAME!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_move(state, neural_network: nn.Module) -> int:\n",
    "    probs = neural_network(state)\n",
    "    probs = probs.cpu().detach().numpy()\n",
    "    move = np.random.choice(range(6), p=probs)\n",
    "    return int(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = nn.Sequential(\n",
    "    nn.Linear(24, 100),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(100, 100),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(100, 6),\n",
    "    nn.Softmax(dim=-1)\n",
    ")\n",
    "\n",
    "V = nn.Sequential(\n",
    "    nn.Linear(24, 100),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(100, 1)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "gamma = 0.99\n",
    "lamda = 0.99\n",
    "erm = EpisodeReplayMemory(gamma, lamda)\n",
    "optimizer_policy = torch.optim.Adam(policy.parameters(), lr=0.001)\n",
    "optimizer_value = torch.optim.Adam(V.parameters(), lr=0.001)\n",
    "\n",
    "episodes_per_stage = 2\n",
    "batch_size = 10  \n",
    "n_stages = 1\n",
    "gradient_steps = 5\n",
    "env = ShooterEnv(opponent_choose_move=choose_move_randomly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [81], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(erm) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size:\n\u001b[1;32m     25\u001b[0m     data \u001b[38;5;241m=\u001b[39m erm\u001b[38;5;241m.\u001b[39msample_with_remove(batch_size)\n\u001b[0;32m---> 26\u001b[0m     states \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mold_observation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     old_probs \u001b[38;5;241m=\u001b[39m policy(states)\n\u001b[1;32m     28\u001b[0m     old_values \u001b[38;5;241m=\u001b[39m V(states)\n",
      "File \u001b[0;32m~/miniconda3/envs/cv38/lib/python3.8/site-packages/torch/cuda/__init__.py:164\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "for stage in range(n_stages):\n",
    "    opponent = deepcopy(policy)\n",
    "    env = ShooterEnv(opponent_choose_move=partial(choose_move, neural_network = opponent), game_speed_multiplier=100_000)\n",
    "    for episode in range(episodes_per_stage):\n",
    "        old_observation, reward, done, info = env.reset()\n",
    "        old_value = V(old_observation)\n",
    "        while not done:\n",
    "            probs = policy(old_observation)\n",
    "            chosen_move = np.random.choice(range(0,6), p=probs.detach().numpy())\n",
    "            observation, reward, done, info = env.step(int(chosen_move))\n",
    "            value = V(observation)\n",
    "            \n",
    "            erm.append({\n",
    "                'old_observation': [old_observation],\n",
    "                'observation': [observation],\n",
    "                'reward': reward,\n",
    "                'done': done,\n",
    "                'chosen_move': chosen_move,\n",
    "                'value': value.item(),\n",
    "                'old_value': old_value.item()\n",
    "            })\n",
    "            old_value = value\n",
    "            \n",
    "        if len(erm) >= batch_size:\n",
    "            data = erm.sample_with_remove(batch_size)\n",
    "            states = data['old_observation'].to(device)\n",
    "            old_probs = policy(states)\n",
    "            old_values = V(states)\n",
    "            \n",
    "            # value function\n",
    "            loss_v = F.smooth_l1_loss(old_values[:,0], data['gae'][0])\n",
    "            optimizer_value.zero_grad()\n",
    "            loss_v.backward()\n",
    "            optimizer_value.step()\n",
    "            \n",
    "            \n",
    "            # policy\n",
    "            epsilon = 0.01\n",
    "            old_probs = old_probs[range(batch_size), data['chosen_move'].long()].detach()\n",
    "            for step in range(gradient_steps):\n",
    "                print('========')\n",
    "                print('making a grad step...')\n",
    "                new_probs = policy(data['old_observation'])#[0]\n",
    "                new_probs = new_probs[range(batch_size), data['chosen_move'].long()]\n",
    "                print(f'unclipped prob_ratio: {new_probs / old_probs}')\n",
    "                prob_ratio = new_probs / old_probs\n",
    "                prob_ratio = torch.clamp(prob_ratio, 1-epsilon, 1+epsilon)\n",
    "                print(f'after clipping: {prob_ratio}')\n",
    "                loss_policy = (- prob_ratio * data['gae']).sum()\n",
    "                print(f'loss: {loss_policy.item()}')\n",
    "                optimizer_policy.zero_grad()\n",
    "                loss_policy.backward()\n",
    "                optimizer_policy.step()\n",
    "                old_probs = new_probs.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1214"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(erm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1775, 0.1418, 0.1555, 0.1769, 0.1842, 0.1641],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'atan2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matan2\u001b[49m(state[\u001b[38;5;241m2\u001b[39m], state[\u001b[38;5;241m3\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/cv38/lib/python3.8/site-packages/numpy/__init__.py:303\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tester\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tester\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'atan2'"
     ]
    }
   ],
   "source": [
    "np.atan2(state[2], state[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.move()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.0000e-01,  0.0000e+00, -1.0000e+00, -1.8370e-16, -8.0000e-01,\n",
       "         0.0000e+00, -1.0000e+00, -1.8370e-16, -1.0000e+00, -1.0000e+00,\n",
       "         0.0000e+00,  1.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00,\n",
       "         1.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "        -1.0000e+00, -1.0000e+00,  0.0000e+00,  1.0000e+00])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.0000e-01,  0.0000e+00, -1.0000e+00, -1.8370e-16, -8.0000e-01,\n",
       "         0.0000e+00, -1.0000e+00, -1.8370e-16, -1.0000e+00, -1.0000e+00,\n",
       "         0.0000e+00,  1.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00,\n",
       "         1.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "        -1.0000e+00, -1.0000e+00,  0.0000e+00,  1.0000e+00])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.round?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_shooter(\n",
    "    your_choose_move=human_player,\n",
    "    opponent_choose_move=choose_move_randomly,\n",
    "    game_speed_multiplier=1,\n",
    "    render=True,\n",
    "    include_barriers=False,\n",
    "    half_game_size=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv38",
   "language": "python",
   "name": "cv38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
