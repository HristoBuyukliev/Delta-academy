{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05c76a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from functools import partial\n",
    "# from check_submission import check_submission\n",
    "from game_mechanics import (\n",
    "    Connect4Env,\n",
    "    choose_move_randomly,\n",
    "    get_empty_board,\n",
    "    get_piece_longest_line_length,\n",
    "    get_top_piece_row_index,\n",
    "    has_won,\n",
    "    is_column_full,\n",
    "    load_dictionary,\n",
    "    place_piece,\n",
    "    play_connect_4_game,\n",
    "    save_dictionary,\n",
    ")\n",
    "from tqdm import tqdm \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from einops import reduce, rearrange\n",
    "from torchsummary import summary\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "\n",
    "TEAM_NAME = \"WIP\"  # <---- Enter your team name here!\n",
    "assert TEAM_NAME != \"Team Name\", \"Please change your TEAM_NAME!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8c35d3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m network \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m      2\u001b[0m     nn\u001b[38;5;241m.\u001b[39mConv2d(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m20\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m      3\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m      4\u001b[0m     nn\u001b[38;5;241m.\u001b[39mDropout2d(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m),\n\u001b[0;32m      5\u001b[0m     nn\u001b[38;5;241m.\u001b[39mBatchNorm2d(\u001b[38;5;241m20\u001b[39m),\n\u001b[0;32m      6\u001b[0m     nn\u001b[38;5;241m.\u001b[39mConv2d(\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m20\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m      7\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m      8\u001b[0m     nn\u001b[38;5;241m.\u001b[39mDropout2d(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m),\n\u001b[0;32m      9\u001b[0m     nn\u001b[38;5;241m.\u001b[39mBatchNorm2d(\u001b[38;5;241m20\u001b[39m),\n\u001b[0;32m     10\u001b[0m     nn\u001b[38;5;241m.\u001b[39mConv2d(\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m20\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     11\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m     12\u001b[0m     nn\u001b[38;5;241m.\u001b[39mDropout2d(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m),\n\u001b[0;32m     13\u001b[0m     nn\u001b[38;5;241m.\u001b[39mBatchNorm2d(\u001b[38;5;241m20\u001b[39m),\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#     Rearrange('b c h w -> b w (h c)'),\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#     nn.Linear(in_features=20*6, out_features=1),\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#     Rearrange('b w 1 -> b w'),\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#     nn.Softmax()\u001b[39;00m\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# network.to(device)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m network(torch_board)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "network = nn.Sequential(\n",
    "    nn.Conv2d(1,20, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout2d(p=0.1),\n",
    "    nn.BatchNorm2d(20),\n",
    "    nn.Conv2d(20,20, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout2d(p=0.1),\n",
    "    nn.BatchNorm2d(20),\n",
    "    nn.Conv2d(20,20, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout2d(p=0.1),\n",
    "    nn.BatchNorm2d(20),\n",
    "#     Rearrange('b c h w -> b w (h c)'),\n",
    "#     nn.Linear(in_features=20*6, out_features=1),\n",
    "#     Rearrange('b w 1 -> b w'),\n",
    "#     nn.Softmax()\n",
    ")\n",
    "# network.to(device)\n",
    "network(torch_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed23e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameTree:\n",
    "    '''\n",
    "    Branches and prunes the tree on a greedy basis\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, max_branches: List[int], env, eval_fn):\n",
    "        self.max_branches = max_branchings\n",
    "        self.env = env\n",
    "        self.state = state\n",
    "        self.objective = 1 # or -1 for opponent\n",
    "        self.ply_depth = len(max_branches)\n",
    "        self.children = []\n",
    "        self.value = None\n",
    "        \n",
    "    def _spawn_children(self):\n",
    "        \n",
    "        \n",
    "    def play(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6315510",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bf8a3ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train() -> nn.Module:\n",
    "    \"\"\"\n",
    "    TODO: Write this function to train your algorithm.\n",
    "\n",
    "    Returns:\n",
    "        Value function dictionary used by your agent. You can\n",
    "         structure this how you like, but choose_move() expects\n",
    "         {feature_vector: value}. If you structure it another\n",
    "         way, you'll have to tweak choose_move().\n",
    "    \"\"\"\n",
    "    size = 4\n",
    "    n_episodes = 10**size\n",
    "    alpha = 0.2\n",
    "    epsilon = 0.1\n",
    "    alpha_decay = 1 - 0.1**size\n",
    "    epsilon_decay = 1 - 0.1**size\n",
    "    gamma = 0.9\n",
    "    value_fn = {}\n",
    "    score = {'won': 0, 'total': 1}\n",
    "    env = Connect4Env()\n",
    "    \n",
    "#     for episode in tqdm(range(n_episodes)):\n",
    "#         state, reward, done, info = env.reset(0)\n",
    "#         while not done:\n",
    "#             old_features = to_feature_vector(state).tobytes()\n",
    "#             old_reward = reward\n",
    "#             move = choose_move(state, value_fn, epsilon=epsilon)\n",
    "#             state, reward, done, info = env.step(move, 0)\n",
    "#             features = to_feature_vector(state).tobytes()\n",
    "#             old_evaluation = value_fn.get(old_features,0)\n",
    "#             new_evaluation = value_fn.get(features,0)\n",
    "#             value_fn[old_features] = old_evaluation*(1-alpha) + alpha*(old_reward + gamma*new_evaluation)\n",
    "#         epsilon *= epsilon_decay\n",
    "#         alpha *= alpha_decay\n",
    "#         value_fn[features] = (1-alpha)*value_fn.get(features, 0) + alpha*reward\n",
    "# #         score['total'] += 1\n",
    "# #         if reward == 1:\n",
    "# #             score['won'] += 1\n",
    "# #         if score['won'] / score['total'] > 0.6 and score['total'] > 20:\n",
    "# #             print(score)\n",
    "# #             print(f'60% winrate at reached at episode {episode}, upgrading opponent...')\n",
    "# #             env._opponent_choose_move = partial(choose_move, value_function=deepcopy(value_fn), epsilon=0)\n",
    "# #             score = {'won': 0, 'total': 1}\n",
    "#     return value_fn\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
