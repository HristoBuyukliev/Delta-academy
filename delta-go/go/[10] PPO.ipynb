{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "841722ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from einops.layers.torch import Rearrange\n",
    "from einops import rearrange\n",
    "\n",
    "from typing import Any, Dict, Tuple, Optional\n",
    "from game_mechanics import GoEnv, choose_move_randomly, load_pkl, play_go, save_pkl\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from utils import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acf170d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "703c7d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_move(observation, legal_moves, neural_network: nn.Module) -> int:\n",
    "    probs, value = neural_network(observation, legal_moves)\n",
    "    probs = probs[0].cpu().detach().numpy()\n",
    "    move = np.random.choice(range(82), p=probs)\n",
    "    return move\n",
    "\n",
    "def random_move(observation, legal_moves):\n",
    "    return random.choice([m for m in legal_moves])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "954e191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaGoZeroBatch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            Rearrange('b w h -> b 1 w h'),\n",
    "            nn.Conv2d(in_channels=1, out_channels=100, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=100, out_channels=100, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=100, out_channels=1, kernel_size=1),\n",
    "            nn.LeakyReLU(),\n",
    "            Rearrange('b c w h -> b (c w h)')\n",
    "        )\n",
    "        \n",
    "        self.tower1 = nn.Sequential(\n",
    "            nn.Linear(81,100),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(100,82)\n",
    "        )\n",
    "        \n",
    "        self.tower2 = nn.Sequential(\n",
    "            nn.Linear(81,1),\n",
    "            nn.Tanh()\n",
    "        ) \n",
    "\n",
    "\n",
    "    def forward(self, x, legal_moves):            \n",
    "        illegal = lambda legal: [move not in legal for move in range(82)]\n",
    "        mask = torch.stack([torch.as_tensor(illegal(lm)) for lm in legal_moves])\n",
    "        # remove option for pass, unless only move:\n",
    "        mask[[len(lm) != 1 for lm in legal_moves], 81] = 1\n",
    "        x = self.stem(x)\n",
    "        x1 = self.tower1(x)\n",
    "        x1 = x1.masked_fill(mask, -torch.inf)\n",
    "        x1 = F.softmax(x1, dim=-1)\n",
    "        x2 = self.tower2(x)\n",
    "        return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45248f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedPolicy(nn.module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            Rearrange('b w h -> b 1 w h'),\n",
    "            nn.Conv2d(in_channels=1, out_channels=100, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=100, out_channels=100, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=100, out_channels=1, kernel_size=1),\n",
    "            nn.LeakyReLU(),\n",
    "            Rearrange('b c w h -> b (c w h)'),\n",
    "            nn.Linear(100, 82)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, legal_moves):\n",
    "        illegal = lambda legal: [move not in legal for move in range(82)]\n",
    "        mask = torch.stack([torch.as_tensor(illegal(lm)) for lm in legal_moves])\n",
    "        # remove option for pass, unless only move:\n",
    "        mask[[len(lm) != 1 for lm in legal_moves], 81] = 1\n",
    "        x = self.net(x)\n",
    "        x = x.masked_fill(mask, -torch.inf)\n",
    "        return F.softmax(x)\n",
    "    \n",
    "class VNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "policy = MaskedPolicy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "8620b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(observation: np.ndarray) -> torch.Tensor:\n",
    "    return torch.as_tensor(observation, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "aa37cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "opponent_choose_move = random_move\n",
    "game_speed_multiplier=1000000\n",
    "render=False\n",
    "verbose=False\n",
    "env = GoEnv(\n",
    "    opponent_choose_move,\n",
    "    verbose=verbose,\n",
    "    render=render,\n",
    "    game_speed_multiplier=game_speed_multiplier,\n",
    ")\n",
    "\n",
    "\n",
    "metrics = []\n",
    "test_eval_size = []\n",
    "\n",
    "num_episodes = 10_000\n",
    "num_test_episodes = 25\n",
    "block_train_episodes = 100\n",
    "gamma = 0.98\n",
    "lamda = 0.9\n",
    "total_score = 0\n",
    "total_played = 0\n",
    "train_rewards = []\n",
    "train_losses = {\n",
    "    'policy': [],\n",
    "    'value': []\n",
    "}\n",
    "\n",
    "\n",
    "memory = 2000\n",
    "batch_size = 20\n",
    "gradient_steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "e2754f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demean(vector, dim=1, eps=1e-5):\n",
    "    '''\n",
    "    convert to mean 0, std 1\n",
    "    '''\n",
    "    vector = torch.as_tensor(vector, dtype=torch.float32)\n",
    "    vector = vector - vector.mean(axis=dim)\n",
    "    vector = vector / (vector.std(axis=dim) + eps)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "b8ef588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stable_baselines3 as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "02546744",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Your environment must inherit from the gym.Env class cf https://github.com/openai/gym/blob/master/gym/core.py",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [280]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_checker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\env_checker.py:259\u001b[0m, in \u001b[0;36mcheck_env\u001b[1;34m(env, warn, skip_render_check)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_env\u001b[39m(env: gym\u001b[38;5;241m.\u001b[39mEnv, warn: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, skip_render_check: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03m    Check that an environment follows Gym API.\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m    This is particularly useful when using a custom environment.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03m        True by default (useful for the CI)\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 259\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    260\u001b[0m         env, gym\u001b[38;5;241m.\u001b[39mEnv\n\u001b[0;32m    261\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour environment must inherit from the gym.Env class cf https://github.com/openai/gym/blob/master/gym/core.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;66;03m# ============= Check the spaces (observation and action) ================\u001b[39;00m\n\u001b[0;32m    264\u001b[0m     _check_spaces(env)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Your environment must inherit from the gym.Env class cf https://github.com/openai/gym/blob/master/gym/core.py"
     ]
    }
   ],
   "source": [
    "sb.common.env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97111fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "3b6fa9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336e61080f7745a88b33071c1d3b9960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [275]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m     17\u001b[0m     probs, value \u001b[38;5;241m=\u001b[39m agzb(rearrange(old_observation, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw h -> 1 w h\u001b[39m\u001b[38;5;124m'\u001b[39m), legal_moves \u001b[38;5;241m=\u001b[39m [legal_moves])\n\u001b[1;32m---> 18\u001b[0m     chosen_move \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m82\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     observation, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(chosen_move)\n\u001b[0;32m     20\u001b[0m     observation \u001b[38;5;241m=\u001b[39m normalize(observation)\n",
      "File \u001b[1;32mmtrand.pyx:935\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "erm = EpisodeReplayMemory(gamma, lamda)\n",
    "agzb = AlphaGoZeroBatch()\n",
    "optimizer = torch.optim.AdamW(agzb.parameters(), lr=0.001)\n",
    "experiment_name = 'PPO_v2' # actually change to PPO\n",
    "experiment_name = 'PPO_v3' # normalize gaes within batch\n",
    "\n",
    "\n",
    "for episode in tqdm(range(num_episodes)):\n",
    "    old_observation, reward, done, info = env.reset()\n",
    "    old_observation = normalize(old_observation)\n",
    "    observation = old_observation\n",
    "    legal_moves = info['legal_moves']\n",
    "    policy_losses = []\n",
    "    value_losses = []\n",
    "    entropy_losses = []\n",
    "    while not done:\n",
    "        probs, value = agzb(rearrange(old_observation, 'w h -> 1 w h'), legal_moves = [legal_moves])\n",
    "        chosen_move = np.random.choice(range(0,82), p=probs[0].detach().numpy())\n",
    "        observation, reward, done, info = env.step(chosen_move)\n",
    "        observation = normalize(observation)\n",
    "        \n",
    "        erm.append({\n",
    "            'old_observation': [old_observation],\n",
    "            'observation': [observation],\n",
    "            'reward': reward,\n",
    "            'done': done,\n",
    "            'old_legal_moves': [legal_moves],\n",
    "            'legal_moves': [info['legal_moves']],\n",
    "            'chosen_move': chosen_move,\n",
    "            'value': value.item()\n",
    "        })\n",
    "        old_observation = observation\n",
    "        legal_moves = info['legal_moves']\n",
    "        \n",
    "    if len(erm) >= memory:\n",
    "        data = erm.sample(batch_size)\n",
    "        old_probs, old_values = agzb(data['old_observation'], data['old_legal_moves'])\n",
    "        loss_v = F.smooth_l1_loss(old_values[:,0], data['gae'][0])\n",
    "        optimizer.zero_grad()\n",
    "        loss_v.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epsilon = 0.01\n",
    "        old_probs = old_probs[range(batch_size), data['chosen_move'].long()].detach()\n",
    "        for step in range(gradient_steps):\n",
    "#             print('========')\n",
    "#             print('making a grad step...')\n",
    "            new_probs = agzb(data['old_observation'], data['old_legal_moves'])[0]\n",
    "            new_probs = new_probs[range(batch_size), data['chosen_move'].long()]\n",
    "#             print(f'unclipped prob_ratio: {new_probs / old_probs}')\n",
    "            prob_ratio = new_probs / old_probs\n",
    "            prob_ratio = torch.clamp(prob_ratio, 1-epsilon, 1+epsilon)\n",
    "#             print(f'after clipping: {prob_ratio}')\n",
    "            loss_policy = (- prob_ratio * demean(data['gae'])).sum()\n",
    "#             print(f'loss: {loss_policy.item()}')\n",
    "            optimizer.zero_grad()\n",
    "            loss_policy.backward()\n",
    "            optimizer.step()\n",
    "            old_probs = new_probs.detach()\n",
    "    \n",
    "    \n",
    "#         for step in range(gradient_steps):\n",
    "# #             loss_policy = -torch.log(probs[range(batch_size), data['chosen_move'].long()])*(data['gae'])\n",
    "# #             loss_entropy = -entropy(probs)\n",
    "#             loss_policy = 3\n",
    "#             loss = loss_v + loss_policy.sum() # + loss_entropy.sum()\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             nn.utils.clip_grad_norm_(agzb.parameters(), 0.1)\n",
    "#             if torch.isnan(agzb.stem[1].weight.grad).sum() == 0:\n",
    "#                 optimizer.step()\n",
    "#             else:\n",
    "#                 print('==============')\n",
    "#                 print(loss_v.sum().item(), loss_policy.sum().item(), loss_entropy.sum().item())\n",
    "#                 print(probs[range(batch_size), data['chosen_move'].long()])\n",
    "#                 print(-torch.log(probs[range(batch_size), data['chosen_move'].long()]))\n",
    "#                 print(data['gae'])\n",
    "#                 print('==============')\n",
    "#                 raise GoError\n",
    "\n",
    "\n",
    "#         entropy_losses.append(loss_entropy.sum().item())\n",
    "        value_losses.append(loss_v.sum().item())\n",
    "        policy_losses.append(loss_policy.sum().item())\n",
    "\n",
    "\n",
    "        # pop data\n",
    "        erm.pop(len(erm) - memory)\n",
    "\n",
    "#             print(rearrange(agzb.stem[1].weight.grad, 'win wout w h -> (win wout w h)'))\n",
    "            \n",
    "\n",
    "        \n",
    "# #     # log stuff\n",
    "#     train_rewards.append(reward)\n",
    "        \n",
    "#     if episode % block_train_episodes == 0:\n",
    "#         rewards = []\n",
    "#         for ep in range(num_test_episodes):\n",
    "#             observation, reward, done, info = env.reset()\n",
    "#             while not done:\n",
    "#                 legal_moves = info['legal_moves']\n",
    "#                 observation = normalize(observation)\n",
    "#                 probs, value = agzb(rearrange(observation, 'w h -> 1 w h'), legal_moves = [legal_moves])\n",
    "#                 chosen_move = np.random.choice(range(0,82), p=probs[0].detach().numpy())\n",
    "#                 observation, reward, done, info = env.step(chosen_move)\n",
    "#             rewards.append(reward)\n",
    "           \n",
    "#         test_wr = sum([r == 1 for r in rewards])/num_test_episodes\n",
    "#         test_score = sum(rewards)/num_test_episodes\n",
    "#         test_ties = sum([r == 0 for r in rewards])/num_test_episodes\n",
    "        \n",
    "#         train_wr = sum([r == 1 for r in train_rewards])/block_train_episodes\n",
    "#         train_score = sum(train_rewards)/block_train_episodes\n",
    "#         train_ties = sum([r == 0 for r in train_rewards])/block_train_episodes\n",
    "#         train_rewards = []\n",
    "#         metrics.append({'test_win_rate': test_wr,\n",
    "#                         'test_score': test_score,\n",
    "#                         'test_ties': test_ties,\n",
    "#                         'train_win_rate': train_wr,\n",
    "#                         'train_score': train_score,\n",
    "#                         'train_ties': train_ties,\n",
    "#                         'episode': episode,\n",
    "#                         'total_score': total_score,\n",
    "#                         'total_played': total_played,\n",
    "#                         'train_loss_policy': sum(policy_losses)/(len(policy_losses)+1),\n",
    "#                         'train_loss_value': sum(value_losses)/(len(value_losses)+1)\n",
    "#                        })\n",
    "\n",
    "#         pd.DataFrame(metrics).to_csv(f'logs/{experiment_name}_{episode}.csv')\n",
    "#         train_losses = {\n",
    "#             'policy': [],\n",
    "#             'value': []\n",
    "#         }\n",
    "\n",
    "#     total_score += reward\n",
    "#     total_played += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4ea85b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9000, 0.9000, 1.0000, 0.9000, 1.0016, 0.9000, 0.9000, 0.9000, 0.9000,\n",
       "         0.9000, 1.0000, 1.0000, 0.9000, 1.0000, 1.0000, 0.9000, 0.9000, 1.1000,\n",
       "         0.9000, 0.9000]], grad_fn=<ClampBackward1>)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "bb550965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]], grad_fn=<DivBackward0>)\n",
      "loss: 0.7653517127037048\n",
      "tensor([[0.9720, 0.9970, 0.9700, 0.9837, 1.0023, 0.9953, 0.9948, 0.9936, 0.9894,\n",
      "         0.9932, 0.9903, 1.0027, 0.9997, 1.0015, 1.0003, 1.0053, 1.0035, 0.9942,\n",
      "         0.9951, 0.9949]], grad_fn=<DivBackward0>)\n",
      "loss: 0.7429934144020081\n",
      "tensor([[0.9366, 0.9889, 0.9491, 1.0005, 0.9948, 0.9837, 1.0023, 1.0003, 0.9814,\n",
      "         0.9876, 0.9469, 1.0244, 0.9940, 1.0140, 0.9873, 0.9945, 1.0007, 0.9981,\n",
      "         0.9693, 1.0111]], grad_fn=<DivBackward0>)\n",
      "loss: 0.7247187495231628\n",
      "tensor([[0.8657, 0.9967, 0.9061, 1.0416, 0.9956, 0.9767, 0.9880, 1.0071, 0.9768,\n",
      "         0.9639, 0.8841, 0.9898, 1.0312, 0.9976, 0.9499, 0.9425, 0.9947, 0.9710,\n",
      "         0.9085, 1.0140]], grad_fn=<DivBackward0>)\n",
      "loss: 0.6947099566459656\n",
      "tensor([[0.8709, 0.9938, 0.8246, 1.0224, 1.0266, 0.9647, 0.9883, 1.0124, 0.9450,\n",
      "         0.9330, 0.8775, 0.9900, 1.0310, 0.9942, 0.9422, 0.9769, 0.9823, 0.9900,\n",
      "         0.9031, 0.9868]], grad_fn=<DivBackward0>)\n",
      "loss: 0.6896411776542664\n",
      "tensor([[0.8839, 0.9891, 0.7961, 0.9835, 1.0151, 0.9553, 1.0001, 1.0009, 0.9377,\n",
      "         0.9097, 0.9056, 0.9930, 1.0173, 0.9829, 0.9639, 1.0196, 0.9939, 0.9851,\n",
      "         0.9075, 0.9806]], grad_fn=<DivBackward0>)\n",
      "loss: 0.687750518321991\n",
      "tensor([[0.8787, 0.9823, 0.7619, 0.9586, 0.9986, 0.9517, 1.0087, 0.9921, 0.9324,\n",
      "         0.8922, 0.8777, 1.0111, 1.0170, 0.9720, 0.9550, 1.0539, 0.9992, 0.9791,\n",
      "         0.9061, 0.9741]], grad_fn=<DivBackward0>)\n",
      "loss: 0.6859743595123291\n",
      "tensor([[0.8959, 0.9759, 0.7470, 0.9282, 0.9753, 0.9445, 1.0152, 0.9844, 0.9273,\n",
      "         0.8918, 0.8932, 1.0270, 1.0007, 0.9626, 0.9671, 1.0755, 0.9951, 0.9755,\n",
      "         0.9105, 0.9762]], grad_fn=<DivBackward0>)\n",
      "loss: 0.6846680045127869\n",
      "tensor([[0.9062, 0.9631, 0.7344, 0.9072, 0.9762, 0.9374, 1.0120, 1.0006, 0.9208,\n",
      "         0.8898, 0.9027, 1.0334, 0.9909, 0.9532, 0.9719, 1.0556, 1.0155, 0.9728,\n",
      "         0.9066, 0.9761]], grad_fn=<DivBackward0>)\n",
      "loss: 0.6857121586799622\n",
      "tensor([[0.7301, 0.9129, 0.6632, 0.9162, 1.0111, 0.9221, 0.9830, 1.0111, 0.8879,\n",
      "         0.8494, 0.8065, 1.0314, 1.0195, 0.9384, 0.9187, 1.0665, 0.9824, 0.9587,\n",
      "         0.8313, 0.9575]], grad_fn=<DivBackward0>)\n",
      "loss: 0.6843873858451843\n",
      "tensor([[0.7148, 0.8917, 0.6365, 0.8844, 1.0192, 0.9045, 0.9693, 1.0096, 0.8778,\n",
      "         0.8386, 0.7972, 1.0428, 1.0155, 0.9239, 0.9103, 1.0860, 0.9778, 0.9458,\n",
      "         0.8085, 0.9483]], grad_fn=<DivBackward0>)\n",
      "loss: 0.6833722591400146\n",
      "tensor([[0.7030, 0.8788, 0.6174, 0.8747, 1.0290, 0.8861, 0.9491, 1.0075, 0.8680,\n",
      "         0.8291, 0.7916, 1.0564, 1.0057, 0.9090, 0.9031, 1.1151, 0.9735, 0.9283,\n",
      "         0.7912, 0.9361]], grad_fn=<DivBackward0>)\n",
      "loss: 0.6828433871269226\n",
      "tensor([[0.6979, 0.8661, 0.6145, 0.8666, 1.0230, 0.9005, 0.9367, 1.0274, 0.8671,\n",
      "         0.8262, 0.7909, 1.0727, 0.9859, 0.8911, 0.8985, 1.1089, 0.9786, 0.9117,\n",
      "         0.7810, 0.9490]], grad_fn=<DivBackward0>)\n",
      "loss: 0.68266761302948\n",
      "tensor([[0.6960, 0.8497, 0.6171, 0.8620, 1.0190, 0.8858, 0.9285, 1.0326, 0.8637,\n",
      "         0.8232, 0.7921, 1.0862, 0.9662, 0.8844, 0.8991, 1.0969, 0.9779, 0.8960,\n",
      "         0.7748, 0.9495]], grad_fn=<DivBackward0>)\n",
      "loss: 0.6826575398445129\n",
      "tensor([[0.6963, 0.8437, 0.6181, 0.8594, 1.0019, 0.8913, 0.9329, 1.0243, 0.8584,\n",
      "         0.8245, 0.7980, 1.1004, 0.9514, 0.8852, 0.9043, 1.1337, 0.9874, 0.8936,\n",
      "         0.7706, 0.9532]], grad_fn=<DivBackward0>)\n",
      "loss: 0.6824958920478821\n",
      "tensor([[0.7002, 0.8401, 0.6281, 0.8608, 0.9954, 0.9067, 0.9258, 1.0295, 0.8609,\n",
      "         0.8272, 0.8030, 1.0908, 0.9306, 0.8826, 0.9033, 1.1284, 0.9901, 0.8900,\n",
      "         0.7721, 0.9690]], grad_fn=<DivBackward0>)\n",
      "loss: 0.6824177503585815\n",
      "tensor([[0.7066, 0.8252, 0.6414, 0.8616, 0.9927, 0.8885, 0.9191, 1.0341, 0.8569,\n",
      "         0.8245, 0.8083, 1.1063, 0.9125, 0.8782, 0.9032, 1.1225, 0.9894, 0.8872,\n",
      "         0.7713, 0.9688]], grad_fn=<DivBackward0>)\n",
      "loss: 0.6823258399963379\n",
      "tensor([[0.7149, 0.8234, 0.6633, 0.8666, 0.9861, 0.9042, 0.9111, 1.0389, 0.8616,\n",
      "         0.8278, 0.8161, 1.0951, 0.8925, 0.8763, 0.9016, 1.1140, 0.9901, 0.8862,\n",
      "         0.7752, 0.9888]], grad_fn=<DivBackward0>)\n",
      "loss: 0.6822414398193359\n",
      "tensor([[0.7210, 0.8154, 0.6797, 0.8716, 0.9844, 0.8859, 0.9052, 1.0446, 0.8618,\n",
      "         0.8274, 0.8169, 1.1117, 0.8880, 0.8743, 0.8993, 1.1080, 0.9882, 0.8868,\n",
      "         0.7783, 0.9929]], grad_fn=<DivBackward0>)\n",
      "loss: 0.6821979284286499\n",
      "tensor([[0.7300, 0.8223, 0.7026, 0.8754, 0.9777, 0.9075, 0.8987, 1.0497, 0.8717,\n",
      "         0.8366, 0.8217, 1.1004, 0.8858, 0.8760, 0.8988, 1.0983, 0.9887, 0.8890,\n",
      "         0.7862, 1.0187]], grad_fn=<DivBackward0>)\n",
      "loss: 0.6821842789649963\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.1\n",
    "data = erm.sample(batch_size)\n",
    "old_probs, old_values = agzb(data['old_observation'], data['old_legal_moves'])\n",
    "loss_v = F.smooth_l1_loss(values[:,0], data['gae'][0])\n",
    "new_probs = old_probs[range(batch_size), data['chosen_move'].long()]\n",
    "old_probs = old_probs[range(batch_size), data['chosen_move'].long()].detach()\n",
    "for step in range(gradient_steps):\n",
    "    print(new_probs / old_probs)\n",
    "    prob_ratio = new_probs / old_probs\n",
    "    prob_ratio = torch.clamp(prob_ratio, 1-epsilon, 1+epsilon)\n",
    "    loss_policy = (- prob_ratio * data['gae']).sum()\n",
    "    print(f'loss: {loss_policy.item()}')\n",
    "    optimizer.zero_grad()\n",
    "    loss_policy.backward()\n",
    "    optimizer.step()\n",
    "    old_probs = new_probs.detach()\n",
    "    new_probs = agzb(data['old_observation'], data['old_legal_moves'])[0][range(batch_size), data['chosen_move'].long()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7e8d9714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0060, 1.0904, 1.1360, 0.9289, 1.0531, 1.4913, 0.9691, 0.9812, 0.8563,\n",
      "         1.0044, 0.9955, 0.9851, 0.9150, 1.0844, 0.9109, 0.9422, 0.9792, 0.9196,\n",
      "         0.9358, 0.9541]], grad_fn=<DivBackward0>)\n",
      "loss: -0.30770641565322876\n",
      "tensor([[0.9941, 1.1003, 1.1780, 0.8801, 1.0263, 1.4923, 0.9475, 0.9663, 0.8130,\n",
      "         0.9945, 0.9749, 0.9696, 0.8817, 1.0771, 0.8796, 0.9149, 0.9567, 0.8714,\n",
      "         0.9151, 0.9125]], grad_fn=<DivBackward0>)\n",
      "loss: -0.3103961646556854\n",
      "tensor([[0.9813, 1.1364, 1.2316, 0.8379, 1.0006, 1.3825, 0.9223, 0.9419, 0.7448,\n",
      "         0.9784, 0.9522, 0.9412, 0.8473, 1.0560, 0.8356, 0.8937, 0.9313, 0.8097,\n",
      "         0.8881, 0.8758]], grad_fn=<DivBackward0>)\n",
      "loss: -0.29622897505760193\n",
      "tensor([[0.9644, 1.2121, 1.3059, 0.7793, 0.9695, 1.1946, 0.8975, 0.9138, 0.6705,\n",
      "         0.9601, 0.9238, 0.9042, 0.7977, 1.0209, 0.7944, 0.8580, 0.8976, 0.7395,\n",
      "         0.8657, 0.8208]], grad_fn=<DivBackward0>)\n",
      "loss: -0.27125832438468933\n",
      "tensor([[0.9289, 1.2767, 1.3419, 0.7127, 0.9332, 1.0670, 0.8670, 0.8856, 0.5922,\n",
      "         0.9383, 0.8823, 0.8681, 0.7467, 0.9557, 0.7609, 0.8111, 0.8399, 0.6497,\n",
      "         0.8439, 0.7489]], grad_fn=<DivBackward0>)\n",
      "loss: -0.2541644275188446\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "612152c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.2582e-04,  8.0896e-01,  6.5621e-04,  1.4040e-03,  5.9832e-04,\n",
       "          1.0874e-03,  1.8557e-04,  5.9848e-04,  5.5689e-03,  1.0085e-03,\n",
       "          7.1289e-04,  6.2720e-04, -2.3690e-03,  9.1954e-04,  1.6345e-02,\n",
       "          1.7020e-04, -2.3217e-04,  8.4265e-05,  6.7754e-04,  5.0323e-04]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9feff3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2118, grad_fn=<SmoothL1LossBackward0>)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e443e74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0275, 0.0203, 0.1484, 0.0185, 0.1920, 0.0140, 0.2300, 0.1008, 0.1252,\n",
       "         0.0236, 0.0782, 0.0609, 0.0778, 0.0263, 0.0951, 0.0212, 0.0275, 0.1023,\n",
       "         0.0737, 0.1652]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_probs[range(batch_size), data['chosen_move'].long()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2514633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(gradient_steps):\n",
    "#             loss_policy = -torch.log(probs[range(batch_size), data['chosen_move'].long()])*(data['gae'])\n",
    "#             loss_entropy = -entropy(probs)\n",
    "    loss_policy = 3\n",
    "    loss = loss_v + loss_policy.sum() # + loss_entropy.sum()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(agzb.parameters(), 0.1)\n",
    "    if torch.isnan(agzb.stem[1].weight.grad).sum() == 0:\n",
    "        optimizer.step()\n",
    "    else:\n",
    "        print('==============')\n",
    "        print(loss_v.sum().item(), loss_policy.sum().item(), loss_entropy.sum().item())\n",
    "        print(probs[range(batch_size), data['chosen_move'].long()])\n",
    "        print(-torch.log(probs[range(batch_size), data['chosen_move'].long()]))\n",
    "        print(data['gae'])\n",
    "        print('==============')\n",
    "        raise GoError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c28645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4789b96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf544537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cebe94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9276bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab4f736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8b85e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0377f481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7779c058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e08526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b60cc87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e967b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcb1d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ded78d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4763323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1c85275e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0d7d257e3c43bfa6052c4100a1fc11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "GoError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mGoError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [183]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m entropy_losses\u001b[38;5;241m.\u001b[39mappend(loss_entropy\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_policy\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1000\u001b[39m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GoError\n\u001b[0;32m     51\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     52\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[1;31mGoError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "erm = EpisodeReplayMemory(gamma, lamda)\n",
    "agzb = AlphaGoZeroBatch()\n",
    "optimizer = torch.optim.AdamW(agzb.parameters(), lr=0.001)\n",
    "experiment_name = 'PPO_v0'\n",
    "\n",
    "for episode in tqdm(range(num_episodes)):\n",
    "    old_observation, reward, done, info = env.reset()\n",
    "    old_observation = normalize(old_observation)\n",
    "    observation = old_observation\n",
    "    legal_moves = info['legal_moves']\n",
    "    policy_losses = []\n",
    "    value_losses = []\n",
    "    entropy_losses = []\n",
    "    while not done:\n",
    "        probs, value = agzb(rearrange(observation, 'w h -> 1 w h'), legal_moves = [legal_moves])\n",
    "        chosen_move = np.random.choice(range(0,82), p=probs[0].detach().numpy())\n",
    "        observation, reward, done, info = env.step(chosen_move)\n",
    "        observation = normalize(observation)\n",
    "        \n",
    "        erm.append({\n",
    "            'old_observation': [old_observation],\n",
    "            'observation': [observation],\n",
    "            'reward': reward,\n",
    "            'done': done,\n",
    "            'old_legal_moves': [legal_moves],\n",
    "            'legal_moves': [info['legal_moves']],\n",
    "            'chosen_move': chosen_move,\n",
    "            'value': value.item()\n",
    "        })\n",
    "        old_observation = observation\n",
    "        legal_moves = info['legal_moves']\n",
    "        \n",
    "    if len(erm) >= memory:\n",
    "#         print('making a grad step...')\n",
    "        data = erm.sample(batch_size)\n",
    "        probs, values = agzb(data['old_observation'], data['old_legal_moves'])\n",
    "        loss_v = F.smooth_l1_loss(values[:,0], data['gae'][0])\n",
    "        loss_policy = -torch.log(probs[range(batch_size), data['chosen_move'].long()])*(data['gae'])\n",
    "        loss_entropy = -entropy(probs)\n",
    "        loss = loss_v + loss_policy.sum() # + loss_entropy.sum()\n",
    "        value_losses.append(loss_v.sum().item())\n",
    "        policy_losses.append(loss_policy.sum().item())\n",
    "        entropy_losses.append(loss_entropy.sum().item())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if loss_policy.sum().item() < -1000:\n",
    "            raise GoError\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(agzb.parameters(), 0.1)\n",
    "        if torch.isnan(agzb.stem[1].weight.grad).sum() == 0:\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            print('==============')\n",
    "            print(loss_v.sum().item(), loss_policy.sum().item(), loss_entropy.sum().item())\n",
    "            print(probs[range(batch_size), data['chosen_move'].long()])\n",
    "            print(-torch.log(probs[range(batch_size), data['chosen_move'].long()]))\n",
    "            print(data['gae'])\n",
    "            print('==============')\n",
    "            raise GoError\n",
    "\n",
    "        # pop data\n",
    "        erm.pop(len(erm) - memory)\n",
    "\n",
    "#             print(rearrange(agzb.stem[1].weight.grad, 'win wout w h -> (win wout w h)'))\n",
    "            \n",
    "\n",
    "        \n",
    "#     # log stuff\n",
    "    train_rewards.append(reward)\n",
    "        \n",
    "    if episode % block_train_episodes == 0:\n",
    "        rewards = []\n",
    "        for ep in range(num_test_episodes):\n",
    "            observation, reward, done, info = env.reset()\n",
    "            while not done:\n",
    "                legal_moves = info['legal_moves']\n",
    "                observation = normalize(observation)\n",
    "                probs, value = agzb(rearrange(observation, 'w h -> 1 w h'), legal_moves = [legal_moves])\n",
    "                chosen_move = np.random.choice(range(0,82), p=probs[0].detach().numpy())\n",
    "                observation, reward, done, info = env.step(chosen_move)\n",
    "            rewards.append(reward)\n",
    "           \n",
    "        test_wr = sum([r == 1 for r in rewards])/num_test_episodes\n",
    "        test_score = sum(rewards)/num_test_episodes\n",
    "        test_ties = sum([r == 0 for r in rewards])/num_test_episodes\n",
    "        \n",
    "        train_wr = sum([r == 1 for r in train_rewards])/block_train_episodes\n",
    "        train_score = sum(train_rewards)/block_train_episodes\n",
    "        train_ties = sum([r == 0 for r in train_rewards])/block_train_episodes\n",
    "        train_rewards = []\n",
    "        metrics.append({'test_win_rate': test_wr,\n",
    "                        'test_score': test_score,\n",
    "                        'test_ties': test_ties,\n",
    "                        'train_win_rate': train_wr,\n",
    "                        'train_score': train_score,\n",
    "                        'train_ties': train_ties,\n",
    "                        'episode': episode,\n",
    "                        'total_score': total_score,\n",
    "                        'total_played': total_played,\n",
    "                        'train_loss_policy': sum(policy_losses)/(len(policy_losses)+1),\n",
    "                        'train_loss_value': sum(value_losses)/(len(value_losses)+1)\n",
    "                       })\n",
    "\n",
    "        pd.DataFrame(metrics).to_csv(f'logs/{experiment_name}_{episode}.csv')\n",
    "        train_losses = {\n",
    "            'policy': [],\n",
    "            'value': []\n",
    "        }\n",
    "\n",
    "    total_score += reward\n",
    "    total_played += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c156b494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(erm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1657795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0037301385309547186,\n",
       " -0.024941865354776382,\n",
       " 0.006949669681489468,\n",
       " 0.002547965617850423,\n",
       " -0.0005118795670568943,\n",
       " -0.010659327730536461,\n",
       " 0.00045812781900167465,\n",
       " 0.0015979387098923326,\n",
       " 0.004741208627820015,\n",
       " 0.005046558566391468,\n",
       " -0.03361545503139496,\n",
       " 0.015168051235377789,\n",
       " 0.005205255467444658,\n",
       " -0.022774431854486465,\n",
       " 0.01015450805425644,\n",
       " -0.008700385689735413,\n",
       " -0.0019155567279085517,\n",
       " -0.01162044983357191,\n",
       " -0.01042257621884346,\n",
       " 0.006771334912627935,\n",
       " -0.00803698506206274,\n",
       " 0.002187971491366625,\n",
       " 0.00998406670987606,\n",
       " -0.008172986097633839,\n",
       " 0.0009817909449338913,\n",
       " 0.009564206935465336,\n",
       " 0.0047758230939507484,\n",
       " -0.011998648755252361,\n",
       " -0.017856277525424957,\n",
       " 0.0016945855459198356,\n",
       " 5.4521020501852036e-05,\n",
       " -0.01721285469830036,\n",
       " 0.00843917578458786,\n",
       " -0.015443354845046997,\n",
       " 0.006355703808367252,\n",
       " -0.0013247529277577996,\n",
       " 0.0026575231458991766,\n",
       " 0.003212957875803113,\n",
       " -0.006097408942878246,\n",
       " -0.0067151449620723724,\n",
       " 0.011311236768960953,\n",
       " -0.023048035800457,\n",
       " 0.011541795916855335,\n",
       " -0.002798614325001836,\n",
       " -0.014981652610003948,\n",
       " -0.01999778300523758,\n",
       " -0.01876637153327465,\n",
       " -0.027328403666615486,\n",
       " -0.008512556552886963,\n",
       " 0.004526734817773104,\n",
       " -0.005195904057472944,\n",
       " -0.08363358676433563,\n",
       " 0.008149631321430206,\n",
       " 0.009529050439596176,\n",
       " -0.04112489894032478,\n",
       " 0.003806214313954115,\n",
       " 0.006806725170463324,\n",
       " -0.003445881186053157,\n",
       " -0.03284503147006035,\n",
       " -0.0326659269630909,\n",
       " -0.09896986186504364,\n",
       " -0.00839201733469963,\n",
       " -0.03571654483675957,\n",
       " -0.13462990522384644,\n",
       " -0.049000371247529984,\n",
       " -0.025669416412711143,\n",
       " -0.017143268138170242,\n",
       " -0.021280664950609207,\n",
       " -0.039121486246585846,\n",
       " -0.002700608456507325,\n",
       " -0.00519158411771059,\n",
       " -0.026247631758451462,\n",
       " -0.06121870130300522,\n",
       " -0.009171240963041782,\n",
       " -0.06627006083726883,\n",
       " -0.04673008993268013,\n",
       " -0.394660085439682,\n",
       " -0.07943813502788544,\n",
       " -0.002602699212729931,\n",
       " 0.005257361568510532,\n",
       " -0.07200460135936737,\n",
       " -0.11101026087999344,\n",
       " -0.035423215478658676,\n",
       " -0.018395377323031425,\n",
       " -0.014225185848772526,\n",
       " -0.035407088696956635,\n",
       " -0.09349146485328674,\n",
       " -0.0026072245091199875,\n",
       " 0.004806663375347853,\n",
       " 0.006078823935240507,\n",
       " 0.00670963479205966,\n",
       " -0.18394571542739868,\n",
       " 0.003767321351915598,\n",
       " -0.06926793605089188,\n",
       " -0.05468307062983513,\n",
       " -0.00786854512989521,\n",
       " -0.2522100508213043,\n",
       " 0.009115912020206451,\n",
       " 0.00651836022734642,\n",
       " 0.0017825261456891894,\n",
       " -0.37490978837013245,\n",
       " -0.013974868692457676,\n",
       " -0.0007273678202182055,\n",
       " 0.004684714134782553,\n",
       " -0.41913706064224243,\n",
       " 0.007663877215236425,\n",
       " -0.02544325217604637,\n",
       " 0.00015508932119701058,\n",
       " -0.1370638757944107,\n",
       " -0.0006305553833954036,\n",
       " -0.008232391439378262,\n",
       " -0.0023295674473047256,\n",
       " -0.12223774194717407,\n",
       " 0.02679653838276863,\n",
       " -0.040635496377944946,\n",
       " -0.07925912737846375,\n",
       " -0.057409610599279404,\n",
       " -0.20213593542575836,\n",
       " -0.11756813526153564,\n",
       " -0.02545403689146042,\n",
       " 0.033845700323581696,\n",
       " 0.005609957501292229,\n",
       " -0.09965881705284119,\n",
       " -0.047551725059747696,\n",
       " -0.07147704809904099,\n",
       " -0.01628413051366806,\n",
       " -0.49113529920578003,\n",
       " -0.5237259864807129,\n",
       " -0.42608463764190674,\n",
       " -inf]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e4526af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 23, 34, 38, 58, 65, 76, 81])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legal_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "baac37df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gae(rewards, values, successor_values, gamma, lamda):\n",
    "    N = len(rewards)\n",
    "    deltas = rewards + gamma*successor_values - values\n",
    "    print(deltas)\n",
    "    gamlam = gamma * lamda\n",
    "    print(gamlam)\n",
    "    gamlam_geo_series = torch.as_tensor([gamlam**i for i in range(N)])*(1-gamlam)\n",
    "    print(gamlam_geo_series.sum())\n",
    "    print(gamlam_geo_series)\n",
    "    full_gamlam_matrix = torch.stack([torch.roll(gamlam_geo_series, shifts=n) for n in range(N)])\n",
    "    full_gamlam_matrix = torch.triu(full_gamlam_matrix)\n",
    "    # make sure it sums to one:\n",
    "    # (by making the term for the last value be 1 - sum(all other terms))\n",
    "    full_gamlam_matrix[:,-1] = 1 - full_gamlam_matrix[:,:-1].sum(axis=1)\n",
    "    return full_gamlam_matrix @ deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "183689e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79090cb7-a79f-4187-b318-6bee19e07106    0.053663\n",
      "54a427cd-0d1e-4e3c-aed6-c32cd130e8ca    0.023148\n",
      "044beaba-81ac-407e-8405-1f78e3f71f66   -0.033101\n",
      "1269371b-be6d-42de-adda-9ef1d35b8d38    0.028446\n",
      "800bc267-4783-4a39-9766-51ad3dabeb79    0.062310\n",
      "                                          ...   \n",
      "8d90c664-89fa-4aa7-9b70-20eee6e5d3da   -0.047355\n",
      "200e179d-607b-4afe-85d1-4c3192a8a512   -0.081588\n",
      "1c52109c-577d-47ad-8052-82103ccedc8c   -0.272351\n",
      "c951121d-576b-43ba-91b8-310ce9fda765   -0.110339\n",
      "c760a1cd-c5dd-438c-af02-303ff56d3497   -0.793496\n",
      "Length: 76, dtype: float64\n",
      "0.882\n",
      "tensor(0.9999)\n",
      "tensor([1.1800e-01, 1.0408e-01, 9.1795e-02, 8.0963e-02, 7.1410e-02, 6.2983e-02,\n",
      "        5.5551e-02, 4.8996e-02, 4.3215e-02, 3.8115e-02, 3.3618e-02, 2.9651e-02,\n",
      "        2.6152e-02, 2.3066e-02, 2.0344e-02, 1.7944e-02, 1.5826e-02, 1.3959e-02,\n",
      "        1.2312e-02, 1.0859e-02, 9.5775e-03, 8.4474e-03, 7.4506e-03, 6.5714e-03,\n",
      "        5.7960e-03, 5.1121e-03, 4.5088e-03, 3.9768e-03, 3.5075e-03, 3.0936e-03,\n",
      "        2.7286e-03, 2.4066e-03, 2.1226e-03, 1.8722e-03, 1.6513e-03, 1.4564e-03,\n",
      "        1.2846e-03, 1.1330e-03, 9.9928e-04, 8.8137e-04, 7.7737e-04, 6.8564e-04,\n",
      "        6.0473e-04, 5.3337e-04, 4.7044e-04, 4.1492e-04, 3.6596e-04, 3.2278e-04,\n",
      "        2.8469e-04, 2.5110e-04, 2.2147e-04, 1.9533e-04, 1.7229e-04, 1.5196e-04,\n",
      "        1.3402e-04, 1.1821e-04, 1.0426e-04, 9.1958e-05, 8.1107e-05, 7.1537e-05,\n",
      "        6.3095e-05, 5.5650e-05, 4.9083e-05, 4.3292e-05, 3.8183e-05, 3.3678e-05,\n",
      "        2.9704e-05, 2.6199e-05, 2.3107e-05, 2.0380e-05, 1.7976e-05, 1.5854e-05,\n",
      "        1.3984e-05, 1.2334e-05, 1.0878e-05, 9.5946e-06])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.01706675,  0.01217071,  0.01070203,  0.01656227,  0.01497237,\n",
       "        0.00863929,  0.00485988, -0.00309762, -0.00895774, -0.01382866,\n",
       "       -0.00630588, -0.01161645, -0.01748861, -0.00752516, -0.01405457,\n",
       "       -0.0051386 , -0.00090681,  0.00246415,  0.00802777,  0.00237488,\n",
       "        0.00107258,  0.00914282,  0.00737539,  0.00365904,  0.00518325,\n",
       "        0.01056112,  0.01196938,  0.00168064,  0.00568278, -0.00539965,\n",
       "       -0.00521241, -0.01592977, -0.01018809, -0.00608239, -0.00583005,\n",
       "       -0.00286979, -0.0102057 , -0.01184584, -0.0151518 , -0.01719426,\n",
       "       -0.02541254, -0.02884286, -0.03223855, -0.0393263 , -0.04145166,\n",
       "       -0.04955144, -0.05483385, -0.0514251 , -0.04460295, -0.04899038,\n",
       "       -0.05018361, -0.04704022, -0.07603612, -0.0700813 , -0.08826283,\n",
       "       -0.09690747, -0.10663619, -0.11393048, -0.11967866, -0.12305002,\n",
       "       -0.12550825, -0.13013705, -0.16037103, -0.17989618, -0.19420775,\n",
       "       -0.21929876, -0.24109841, -0.30766229, -0.33327461, -0.39506198,\n",
       "       -0.47343249, -0.5282095 , -0.59254151, -0.6609004 , -0.71288311,\n",
       "       -0.79349563])"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gae(erm.data.reward[-76:], erm.data.value[-76:], np.append(erm.data.value[-75:].values, 0), 0.98, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "f640886a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-27.440486907958984,\n",
       " -21.824899673461914,\n",
       " -27.161766052246094,\n",
       " -0.6968467235565186,\n",
       " -6.4027018547058105,\n",
       " -61.83473587036133,\n",
       " -19.494089126586914,\n",
       " -52.11186599731445,\n",
       " -14.539194107055664,\n",
       " -22.4394474029541,\n",
       " -25.420284271240234,\n",
       " -17.10361671447754,\n",
       " -53.09296798706055,\n",
       " -26.88081932067871,\n",
       " -15.251133918762207,\n",
       " -27.69683074951172,\n",
       " -37.522422790527344,\n",
       " -33.41025924682617,\n",
       " -4.652161598205566,\n",
       " -36.31564712524414,\n",
       " -17.745750427246094,\n",
       " -37.966644287109375,\n",
       " -34.613372802734375,\n",
       " -22.81201171875,\n",
       " -56.3080940246582,\n",
       " -20.445175170898438,\n",
       " -60.870582580566406,\n",
       " -45.934513092041016,\n",
       " -10.51439380645752,\n",
       " -56.14714431762695,\n",
       " -57.362060546875,\n",
       " -73.95291137695312,\n",
       " -33.51780700683594,\n",
       " -31.75788688659668,\n",
       " -20.893056869506836,\n",
       " -2.9542171955108643,\n",
       " -58.07902908325195,\n",
       " -27.55059242248535,\n",
       " -38.236083984375,\n",
       " -30.0587158203125,\n",
       " -63.049713134765625,\n",
       " -44.49853515625,\n",
       " -32.04090118408203,\n",
       " -96.06962585449219,\n",
       " -21.764240264892578,\n",
       " -49.9351806640625,\n",
       " -84.3717041015625]"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "56bb4bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "099cc42a-718f-4ce8-a593-9110b722bf7f    0.131994\n",
       "69ee8cf6-9250-4cc9-ba96-4b8e5bae1da0    0.133866\n",
       "68729b4e-a992-40e5-a658-c1fe4ca56e55    0.135989\n",
       "7ae63035-6d53-4315-98df-59e98551e5be    0.138395\n",
       "b593c584-ff9a-43d0-aab7-5cd646043e52    0.141124\n",
       "                                          ...   \n",
       "5166a343-993b-4f5f-913f-8b23e32a4483   -0.651756\n",
       "a52e7e77-0f37-4705-a5be-68700090c52f   -0.723166\n",
       "72a48304-3e81-41d7-8827-8822d7b6237c   -0.804129\n",
       "b8ed51ce-187a-4f0b-a446-57fd99ca0497   -0.895924\n",
       "e6dc0f1d-7f09-414c-84ad-0744c4498a6b   -1.000000\n",
       "Name: gae, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erm.data.gae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "0348ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = erm.data.value\n",
    "successor_values = np.append(erm.data.value[1:], 0)\n",
    "rewards = erm.data.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "9f12445a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11800009, -0.11800003, -0.11800003, ..., -0.80412894,\n",
       "       -0.89592397, -1.        ])"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gae(rewards, values, successor_values, 0.98, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "9c41937d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10ca640",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1-1/n) + (1-1/n)**2 + ... + (1-1/n)**inf = \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "4ac077c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36ded7c1-340a-40b3-b3ea-b5f8a9b2db4b   -0.000590\n",
      "7b3c73a6-e499-42f8-801d-b3efd2122f13    0.001796\n",
      "6ec5f132-5cf2-4a46-b6e3-913e01d77c66    0.001113\n",
      "1be75976-9f54-4f80-8f66-b4a4fb796d3e    0.001062\n",
      "ba083112-d85a-455f-b12e-4d1041a0c304    0.002020\n",
      "                                          ...   \n",
      "df94ac6d-03bf-4ca1-b666-a5d5618b4815    0.066126\n",
      "e26e7b0a-055b-4b97-a2df-93fc49010861   -0.145267\n",
      "d869a443-c1a2-4af3-8ded-0c124258cd5a    0.035698\n",
      "60e064ba-a622-4760-80a0-07cedb2cc4f3    0.035179\n",
      "c8d02e7d-cce5-4ff5-a4b5-73b86f3379d4   -0.942783\n",
      "Length: 2000, dtype: float64\n",
      "0.882\n",
      "tensor([0.1041, 0.0918, 0.0810,  ..., 0.0000, 0.0000, 0.0000])\n",
      "tensor([[0.1041, 0.0918, 0.0810,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1041, 0.0918,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1041,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1041, 0.0918, 0.0810],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1041, 0.0918],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1041]])\n",
      "tensor([[0.1041, 0.0918, 0.0810,  ..., 0.0000, 0.0000, 0.1180],\n",
      "        [0.0000, 0.1041, 0.0918,  ..., 0.0000, 0.0000, 0.1180],\n",
      "        [0.0000, 0.0000, 0.1041,  ..., 0.0000, 0.0000, 0.1180],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1041, 0.0918, 0.8041],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1041, 0.8959],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "    N = len(rewards)\n",
    "    deltas = rewards + gamma*successor_values - values\n",
    "    print(deltas)\n",
    "    gamlam = gamma * lamda\n",
    "    print(gamlam)\n",
    "    gamlam_geo_series = torch.as_tensor([gamlam**i for i in range(1,N+1)])*(1-gamlam)\n",
    "    print(gamlam_geo_series)\n",
    "    full_gamlam_matrix = torch.stack([torch.roll(gamlam_geo_series, shifts=n) for n in range(N)])\n",
    "    full_gamlam_matrix = torch.triu(full_gamlam_matrix)\n",
    "    # make sure it sums to one:\n",
    "    # (by making the term for the last value be 1 - sum(all other terms))\n",
    "    print(full_gamlam_matrix)\n",
    "    full_gamlam_matrix[:,-1] = 1 - full_gamlam_matrix[:,:-1].sum(axis=1)\n",
    "    print(full_gamlam_matrix)\n",
    "#     return full_gamlam_matrix @ rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1cb425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "06903dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "a57469c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(policy_losses, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "80eba46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange(agzb.stem[1].weight.grad, 'win wout w h -> (win wout w h)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6408a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_policy = -torch.log(probs[range(batch_size), data['chosen_move'].long()])*(data['gae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "3ca3bd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[81., 81., 61., 79., 81., 81., 51., 60.]])"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['chosen_move']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "3f0d37e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = erm.sample(batch_size)\n",
    "probs, values = agzb(data['old_observation'], data['old_legal_moves'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "7ba97da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = agzb.stem(data['old_observation'])\n",
    "x1 = agzb.tower1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "c689a985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Rearrange('b w h -> b 1 w h')\n",
       "  (1): Conv2d(1, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (2): ReLU()\n",
       "  (3): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): Conv2d(100, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): ReLU()\n",
       "  (7): Rearrange('b c w h -> b (c w h)')\n",
       ")"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agzb.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "920d598b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan],\n",
       "          [nan, nan, nan],\n",
       "          [nan, nan, nan]]]], requires_grad=True)"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(agzb.stem.get_submodule('1').parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "c539d27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
       "\n",
       "\n",
       "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_temp = agzb.stem.get_submodule('0')(data['old_observation'])\n",
    "x_temp = agzb.stem.get_submodule('1')(x_temp)\n",
    "x_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "1fcfe93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.],\n",
       "         [ 0.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 0.,  1.,  1.,  1.,  1.,  1.,  0., -1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]],\n",
       "\n",
       "        [[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]],\n",
       "\n",
       "        [[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]],\n",
       "\n",
       "        [[-1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.],\n",
       "         [-1., -1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.],\n",
       "         [ 1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.],\n",
       "         [-1., -1.,  1.,  1.,  1.,  0.,  0., -1.,  1.],\n",
       "         [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  0.,  1.,  1., -1.,  1.]],\n",
       "\n",
       "        [[ 1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.],\n",
       "         [ 0.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [-1.,  0.,  1.,  1.,  1.,  1.,  0., -1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]],\n",
       "\n",
       "        [[ 0.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.],\n",
       "         [ 0.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.],\n",
       "         [ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1., -1.,  0.,  1.],\n",
       "         [-1.,  0.,  1.,  1.,  1.,  1., -1., -1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]],\n",
       "\n",
       "        [[ 0.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.],\n",
       "         [ 0.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.],\n",
       "         [ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  0.,  1.,  1.,  1., -1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1., -1.,  0.,  1.],\n",
       "         [ 0.,  0.,  1.,  1.,  1.,  0., -1., -1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.]],\n",
       "\n",
       "        [[ 1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.],\n",
       "         [ 0.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.],\n",
       "         [ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1., -1.,  0.,  1.],\n",
       "         [-1.,  0.,  1.,  1.,  1.,  1., -1., -1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]]])"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['old_observation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "c0aae3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan, nan, nan, nan, nan, nan]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[range(batch_size), data['chosen_move'].long()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "cf9f468d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1523, -1.0000, -0.5100, -0.0392, -0.0525, -0.0400, -0.0393, -0.0408]])"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c8171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098e1cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            with torch.no_grad():\n",
    "                new_probs, new_values = agzb(data['observation'], data['legal_moves'])\n",
    "            \n",
    "#             loss_v = F.smooth_l1_loss(values[:,0], (data['reward'] + gamma*new_values[0]*(1-data['done']))[0])\n",
    "            loss_v = F.smooth_l1_loss(values[:,0], data['gae'][0])\n",
    "            loss_policy = -torch.log(probs[range(batch_size), data['chosen_move'].long()])*(data['gae'])\n",
    "            loss = (loss_v + loss_policy).sum()\n",
    "            value_losses.append(loss_v.sum().item())\n",
    "            policy_losses.append(loss_policy.sum().item())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(agzb.parameters(), 10)\n",
    "            optimizer.step()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "37f0ebf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [516]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mprobs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchosen_move\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "probs[range(batch_size), data['chosen_move'].long()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "360a0e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 82])"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "75e1c9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[:, data['chosen_move'].long()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128dd566",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_policy = -torch.log(probs[range(batch_size), data['chosen_move'].long()])*(data['gae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "62e52762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000, -0.7856,  0.0000,  0.0000, -2.9664, -3.6239]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "eb00278e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(policy_losses)\n",
    "plt.plot(value_losses)\n",
    "plt.legend(['policy', 'value'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "bf4cd5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.014642732217907906,\n",
       " 0.018630705773830414,\n",
       " 0.04683767631649971,\n",
       " 0.050856832414865494,\n",
       " 0.09128890186548233,\n",
       " 0.04108111560344696,\n",
       " 0.048889387398958206,\n",
       " 0.0391571968793869,\n",
       " 0.01632932387292385,\n",
       " 0.02227049507200718,\n",
       " 0.025274699553847313,\n",
       " 0.046861693263053894,\n",
       " 0.08866816759109497,\n",
       " 0.09038940817117691,\n",
       " 0.08704598248004913,\n",
       " 0.0345674529671669,\n",
       " 0.035304196178913116,\n",
       " 0.04400236904621124,\n",
       " 0.04056328162550926,\n",
       " 0.08419870585203171,\n",
       " 0.03162689507007599,\n",
       " 0.011311449110507965,\n",
       " 0.03195742145180702,\n",
       " 0.03313601016998291,\n",
       " 0.01846647635102272,\n",
       " 0.018551141023635864,\n",
       " 0.1031537652015686,\n",
       " 0.007746596820652485,\n",
       " 0.03015638329088688,\n",
       " 0.007393420673906803,\n",
       " 0.09939071536064148,\n",
       " 0.010102551430463791,\n",
       " 0.007017123978585005,\n",
       " 0.08444192260503769,\n",
       " 0.08278614282608032,\n",
       " 0.035661544650793076,\n",
       " 0.007890569977462292,\n",
       " 0.07533761858940125,\n",
       " 0.10149736702442169,\n",
       " 0.0802885964512825,\n",
       " 0.011148294433951378,\n",
       " 0.09487415850162506,\n",
       " 0.023402292281389236,\n",
       " 0.09263225644826889,\n",
       " 0.07272928208112717,\n",
       " 0.07189378887414932,\n",
       " 0.030543407425284386,\n",
       " 0.005996847990900278,\n",
       " 0.022740311920642853,\n",
       " 0.02762828767299652,\n",
       " 0.0902007669210434,\n",
       " 0.028091806918382645,\n",
       " 0.0034220803063362837,\n",
       " 0.07000377029180527,\n",
       " 0.025353675708174706,\n",
       " 0.08519456535577774,\n",
       " 0.007490282412618399,\n",
       " 0.08938704431056976,\n",
       " 0.02442222647368908,\n",
       " 0.01970410719513893,\n",
       " 0.007284823805093765,\n",
       " 0.008490297943353653,\n",
       " 0.07010509818792343,\n",
       " 0.007725954055786133,\n",
       " 0.0179741308093071,\n",
       " 0.07046440243721008,\n",
       " 0.002476903609931469,\n",
       " 0.02335381507873535,\n",
       " 0.0174635611474514,\n",
       " 0.06835567951202393,\n",
       " 0.021390754729509354,\n",
       " 0.07950279116630554,\n",
       " 0.06432928144931793,\n",
       " 0.06242190673947334,\n",
       " 0.06641214340925217,\n",
       " 0.005923963617533445,\n",
       " 0.0008488018647767603,\n",
       " 0.002175217028707266,\n",
       " 0.002091008238494396,\n",
       " 0.0005292945425026119,\n",
       " 0.015930932015180588,\n",
       " 0.005848681088536978,\n",
       " 0.015772957354784012,\n",
       " 0.0805559754371643,\n",
       " 0.07657847553491592,\n",
       " 0.0005884174024686217,\n",
       " 0.06405775994062424,\n",
       " 0.014887106604874134,\n",
       " 0.07921568304300308,\n",
       " 0.06399084627628326,\n",
       " 0.019209370017051697,\n",
       " 0.06265389174222946,\n",
       " 0.06243420019745827,\n",
       " 3.905115954694338e-05,\n",
       " 0.05956175550818443,\n",
       " 0.059411611407995224,\n",
       " 0.05894513055682182,\n",
       " 0.05798821523785591,\n",
       " 0.06131569296121597,\n",
       " 0.004283998627215624,\n",
       " 0.05750122666358948,\n",
       " 0.01694159395992756,\n",
       " 0.05806586146354675,\n",
       " 0.00016341534501407295,\n",
       " 0.060026928782463074,\n",
       " 0.014255660586059093,\n",
       " 0.05970548093318939,\n",
       " 0.016331762075424194,\n",
       " 0.0031668883748352528,\n",
       " 0.003148795338347554,\n",
       " 0.013152701780200005,\n",
       " 0.0006744221900589764,\n",
       " 0.016053423285484314,\n",
       " 0.07225775718688965,\n",
       " 0.0029623706359416246,\n",
       " 0.013023807667195797,\n",
       " 0.05838429927825928,\n",
       " 0.012944539077579975,\n",
       " 0.06864074617624283,\n",
       " 0.07117694616317749,\n",
       " 0.07054594904184341,\n",
       " 0.002934512682259083,\n",
       " 0.015310710296034813,\n",
       " 0.06991297751665115,\n",
       " 0.002871591364964843,\n",
       " 0.054725561290979385,\n",
       " 0.05467908829450607,\n",
       " 0.00039315171306952834,\n",
       " 0.05690526217222214,\n",
       " 0.014895585365593433,\n",
       " 0.05431463569402695,\n",
       " 0.01237430702894926,\n",
       " 0.06836408376693726,\n",
       " 0.06855182349681854,\n",
       " 0.054208073765039444,\n",
       " 0.01229850109666586,\n",
       " 0.05605955794453621,\n",
       " 0.06754433363676071,\n",
       " 0.05611826851963997,\n",
       " 0.002949037589132786,\n",
       " 0.014377609826624393,\n",
       " 0.06696480512619019,\n",
       " 0.05336461588740349,\n",
       " 0.0009510893141850829,\n",
       " 0.0007739623542875051,\n",
       " 0.012015853077173233,\n",
       " 0.011943558230996132,\n",
       " 0.05311557278037071,\n",
       " 0.000977572170086205,\n",
       " 0.06376846134662628,\n",
       " 0.012035638093948364,\n",
       " 0.0012841647258028388,\n",
       " 0.01400632131844759,\n",
       " 0.052880603820085526,\n",
       " 0.05258672311902046,\n",
       " 0.013844969682395458,\n",
       " 0.012106534093618393,\n",
       " 0.0012746112188324332,\n",
       " 0.011823556385934353,\n",
       " 0.003040025010704994,\n",
       " 0.011977140791714191,\n",
       " 0.0544273741543293,\n",
       " 0.012012847699224949,\n",
       " 0.0012481252197176218,\n",
       " 0.001231321832165122,\n",
       " 0.0013653055066242814,\n",
       " 0.013501560315489769,\n",
       " 0.0029723700135946274,\n",
       " 0.06460942327976227,\n",
       " 0.00313669815659523,\n",
       " 0.0029960940591990948,\n",
       " 0.013692312873899937,\n",
       " 0.0013602187391370535,\n",
       " 0.052350517362356186,\n",
       " 0.05373188480734825,\n",
       " 0.05240633711218834,\n",
       " 0.01165285799652338,\n",
       " 0.003080039983615279,\n",
       " 0.0031983221415430307,\n",
       " 0.003192710690200329,\n",
       " 0.0030437984969466925,\n",
       " 0.0013567715650424361,\n",
       " 0.011793915182352066,\n",
       " 0.0031099042389541864,\n",
       " 0.05217740312218666,\n",
       " 0.05210844427347183,\n",
       " 0.0013467582175508142,\n",
       " 0.013257596641778946,\n",
       " 0.0518413744866848,\n",
       " 0.003274558112025261,\n",
       " 0.013300774618983269,\n",
       " 0.013561602681875229,\n",
       " 0.013347532600164413,\n",
       " 0.053809233009815216,\n",
       " 0.0032464424148201942,\n",
       " 0.01341046392917633,\n",
       " 0.053463347256183624,\n",
       " 0.013401898555457592,\n",
       " 0.001564858015626669,\n",
       " 0.0032586134038865566,\n",
       " 0.05330115184187889,\n",
       " 0.05184745043516159,\n",
       " 0.06199447810649872,\n",
       " 0.003147573908790946,\n",
       " 0.012011581100523472,\n",
       " 0.012011270970106125,\n",
       " 0.013555210083723068,\n",
       " 0.0532764233648777,\n",
       " 0.05302365496754646,\n",
       " 0.06179795041680336,\n",
       " 0.0614599771797657,\n",
       " 0.001729482552036643,\n",
       " 0.013434632681310177,\n",
       " 0.05294211581349373,\n",
       " 0.011695906519889832,\n",
       " 0.06120854988694191,\n",
       " 0.06259308755397797,\n",
       " 0.05302668362855911,\n",
       " 0.05146664381027222,\n",
       " 0.05127273499965668,\n",
       " 0.012095004320144653]"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "9454d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_v = F.smooth_l1_loss(values[:,0], data['gae'][0])\n",
    "# loss_policy = -torch.log(probs[range(batch_size), data['chosen_move'].long()])*(data['gae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "2836122e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0526, grad_fn=<SmoothL1LossBackward0>)"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "79068f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "c07501be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0946, -0.0457, -1.0000, -0.0664, -0.0396, -0.1523, -0.0408, -0.0525])"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gae'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "61833d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'old_observation': tensor([[[ 0., -1., -1., -1., -1.,  0., -1.,  0.,  0.],\n",
       "          [ 1., -1.,  0.,  0.,  0., -1.,  1.,  0.,  1.],\n",
       "          [-1.,  0.,  0.,  0.,  0.,  1.,  0.,  1., -1.],\n",
       "          [-1.,  0.,  1.,  1.,  1., -1., -1.,  0.,  0.],\n",
       "          [ 0.,  0., -1.,  1.,  0.,  0.,  0.,  0.,  1.],\n",
       "          [ 0., -1.,  0.,  1.,  1.,  0.,  1.,  0., -1.],\n",
       "          [ 1.,  1.,  1.,  0.,  0.,  0.,  0., -1.,  0.],\n",
       "          [ 0., -1.,  0.,  0., -1.,  0., -1.,  0.,  0.],\n",
       "          [ 0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.]],\n",
       " \n",
       "         [[-1., -1., -1., -1., -1.,  0., -1.,  0.,  0.],\n",
       "          [-1., -1.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
       "          [-1., -1.,  0.,  0., -1., -1.,  0.,  0., -1.],\n",
       "          [-1., -1.,  0.,  0.,  0., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  0.,  0., -1., -1., -1., -1.],\n",
       "          [ 0., -1.,  0.,  0.,  0., -1., -1., -1., -1.],\n",
       "          [ 0.,  0.,  1.,  0.,  0.,  0., -1., -1.,  0.],\n",
       "          [ 0.,  0.,  0., -1., -1.,  0., -1., -1., -1.],\n",
       "          [ 0.,  0.,  1.,  1.,  0., -1., -1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1., -1., -1.,  0., -1.,  1.,  0.],\n",
       "          [-1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.],\n",
       "          [-1., -1.,  1.,  1.,  0.,  1.,  1.,  1., -1.],\n",
       "          [-1., -1.,  1.,  1.,  1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  1.,  1., -1., -1., -1.,  0.],\n",
       "          [ 1., -1.,  1.,  1.,  1., -1.,  0.,  0., -1.],\n",
       "          [ 1.,  1.,  1.,  0.,  1.,  1., -1., -1.,  0.],\n",
       "          [ 1.,  0.,  1.,  0., -1.,  1., -1.,  0., -1.],\n",
       "          [ 1.,  1.,  1.,  1.,  1., -1., -1., -1.,  0.]],\n",
       " \n",
       "         [[-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1., -1., -1., -1.,  1.,  0., -1.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1.,  1., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1.,  1.,  1.,  1., -1., -1., -1., -1., -1.],\n",
       "          [-1.,  0.,  1., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1.,  1.,  1., -1., -1., -1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1.,  0., -1., -1., -1.,  1.,  1., -1.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1.,  0., -1.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1.,  1., -1.,  0., -1., -1., -1., -1.],\n",
       "          [-1.,  1.,  1.,  1., -1., -1., -1., -1., -1.],\n",
       "          [-1.,  0.,  1., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1.,  1.,  1., -1., -1., -1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1., -1., -1.,  0., -1.,  0.,  0.],\n",
       "          [-1., -1.,  0.,  0.,  1., -1.,  1.,  1.,  1.],\n",
       "          [-1., -1.,  0.,  1.,  0.,  1.,  0.,  1., -1.],\n",
       "          [-1., -1.,  1.,  1.,  1., -1., -1.,  0.,  0.],\n",
       "          [ 0., -1., -1.,  1.,  0., -1.,  0.,  0.,  1.],\n",
       "          [ 1., -1.,  1.,  1.,  1.,  0.,  1.,  0., -1.],\n",
       "          [ 1.,  1.,  1., -1.,  1.,  0.,  0., -1.,  0.],\n",
       "          [ 0., -1.,  0.,  0., -1.,  1., -1.,  0., -1.],\n",
       "          [ 1.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.]],\n",
       " \n",
       "         [[-1., -1., -1., -1., -1.,  0., -1.,  0.,  0.],\n",
       "          [-1., -1.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
       "          [-1., -1.,  0.,  0., -1., -1.,  0.,  0., -1.],\n",
       "          [-1., -1.,  0., -1.,  1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  0.,  0., -1., -1., -1., -1.],\n",
       "          [ 0., -1.,  0.,  0.,  0., -1., -1., -1., -1.],\n",
       "          [ 0.,  0.,  1.,  0.,  0.,  0., -1., -1.,  0.],\n",
       "          [ 0.,  0.,  0., -1., -1.,  0., -1., -1., -1.],\n",
       "          [ 0.,  0.,  1.,  1.,  0., -1., -1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1., -1., -1.,  0., -1.,  1.,  0.],\n",
       "          [-1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.],\n",
       "          [-1., -1.,  1.,  1.,  0.,  1.,  1.,  1., -1.],\n",
       "          [-1., -1.,  1.,  1.,  1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  1.,  1., -1., -1., -1.,  0.],\n",
       "          [ 1., -1.,  1.,  1.,  1., -1.,  0., -1., -1.],\n",
       "          [ 1.,  1.,  1.,  0.,  1.,  1., -1., -1.,  0.],\n",
       "          [ 1.,  0.,  1.,  0., -1.,  1., -1.,  0., -1.],\n",
       "          [ 1.,  1.,  1.,  1.,  1., -1., -1., -1.,  0.]]]),\n",
       " 'observation': tensor([[[ 0., -1., -1., -1., -1.,  0., -1.,  0.,  0.],\n",
       "          [ 1., -1.,  0.,  0.,  1., -1.,  1.,  0.,  1.],\n",
       "          [-1.,  0.,  0.,  0.,  0.,  1.,  0.,  1., -1.],\n",
       "          [-1., -1.,  1.,  1.,  1., -1., -1.,  0.,  0.],\n",
       "          [ 0.,  0., -1.,  1.,  0.,  0.,  0.,  0.,  1.],\n",
       "          [ 0., -1.,  0.,  1.,  1.,  0.,  1.,  0., -1.],\n",
       "          [ 1.,  1.,  1.,  0.,  0.,  0.,  0., -1.,  0.],\n",
       "          [ 0., -1.,  0.,  0., -1.,  0., -1.,  0.,  0.],\n",
       "          [ 0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.]],\n",
       " \n",
       "         [[-1., -1., -1., -1., -1.,  0., -1.,  0.,  0.],\n",
       "          [-1., -1.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
       "          [-1., -1.,  0.,  0., -1., -1.,  0.,  0., -1.],\n",
       "          [-1., -1.,  0., -1.,  1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  0.,  0., -1., -1., -1., -1.],\n",
       "          [ 0., -1.,  0.,  0.,  0., -1., -1., -1., -1.],\n",
       "          [ 0.,  0.,  1.,  0.,  0.,  0., -1., -1.,  0.],\n",
       "          [ 0.,  0.,  0., -1., -1.,  0., -1., -1., -1.],\n",
       "          [ 0.,  0.,  1.,  1.,  0., -1., -1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1., -1., -1.,  0., -1.,  1.,  0.],\n",
       "          [-1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.],\n",
       "          [-1., -1.,  1.,  1.,  0.,  1.,  1.,  1., -1.],\n",
       "          [-1., -1.,  1.,  1.,  1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  1.,  1., -1., -1., -1.,  0.],\n",
       "          [ 1., -1.,  1.,  1.,  1., -1.,  0., -1., -1.],\n",
       "          [ 1.,  1.,  1.,  0.,  1.,  1., -1., -1.,  0.],\n",
       "          [ 1.,  0.,  1.,  0., -1.,  1., -1.,  0., -1.],\n",
       "          [ 1.,  1.,  1.,  1.,  1., -1., -1., -1.,  0.]],\n",
       " \n",
       "         [[-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1., -1., -1., -1.,  1.,  0., -1.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1.,  0., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1.,  0.,  0.,  0., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1.,  0., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1.,  0.,  1., -1., -1., -1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1., -1., -1., -1.,  1.,  1., -1.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1.,  0., -1.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1.,  1., -1.,  0., -1., -1., -1., -1.],\n",
       "          [-1.,  1.,  1.,  1., -1., -1., -1., -1., -1.],\n",
       "          [-1.,  0.,  1., -1., -1., -1., -1., -1., -1.],\n",
       "          [-1., -1.,  1.,  1., -1., -1., -1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1., -1., -1.,  0., -1.,  0.,  0.],\n",
       "          [-1., -1.,  1.,  0.,  1., -1.,  1.,  1.,  1.],\n",
       "          [-1., -1.,  0.,  1.,  0.,  1.,  0.,  1., -1.],\n",
       "          [-1., -1.,  1.,  1.,  1., -1., -1.,  0.,  0.],\n",
       "          [ 0., -1., -1.,  1.,  0., -1.,  0., -1.,  1.],\n",
       "          [ 1., -1.,  1.,  1.,  1.,  0.,  1.,  0., -1.],\n",
       "          [ 1.,  1.,  1., -1.,  1.,  0.,  0., -1.,  0.],\n",
       "          [ 0., -1.,  0.,  0., -1.,  1., -1.,  0., -1.],\n",
       "          [ 1.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.]],\n",
       " \n",
       "         [[-1., -1., -1., -1., -1.,  0., -1.,  0.,  0.],\n",
       "          [-1., -1.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
       "          [-1., -1.,  0., -1., -1., -1.,  0.,  0., -1.],\n",
       "          [-1., -1.,  0., -1.,  1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  1.,  0., -1., -1., -1., -1.],\n",
       "          [ 0., -1.,  0.,  0.,  0., -1., -1., -1., -1.],\n",
       "          [ 0.,  0.,  1.,  0.,  0.,  0., -1., -1.,  0.],\n",
       "          [ 0.,  0.,  0., -1., -1.,  0., -1., -1., -1.],\n",
       "          [ 0.,  0.,  1.,  1.,  0., -1., -1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1., -1., -1.,  0., -1.,  1.,  0.],\n",
       "          [-1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.],\n",
       "          [-1., -1.,  1.,  1.,  0.,  1.,  1.,  1., -1.],\n",
       "          [-1., -1.,  1.,  1.,  1., -1., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  1.,  1., -1., -1., -1.,  0.],\n",
       "          [ 1., -1.,  1.,  1.,  1., -1., -1., -1., -1.],\n",
       "          [ 1.,  1.,  1.,  0.,  1.,  1., -1., -1.,  0.],\n",
       "          [ 1.,  0.,  1.,  0., -1.,  1., -1.,  0., -1.],\n",
       "          [ 1.,  1.,  1.,  1.,  1., -1., -1., -1.,  0.]]]),\n",
       " 'reward': tensor([[0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " 'done': tensor([[0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " 'old_legal_moves': array([array([ 0,  5,  7,  8, 11, 12, 13, 16, 19, 20, 21, 22, 24, 28, 34, 35, 36,\n",
       "               37, 40, 41, 42, 43, 45, 47, 50, 52, 57, 58, 59, 60, 62, 63, 65, 66,\n",
       "               68, 70, 71, 72, 74, 75, 77, 79, 80, 81])                           ,\n",
       "        array([ 5,  7,  8, 11, 12, 13, 15, 16, 17, 20, 21, 24, 25, 29, 30, 31, 39,\n",
       "               40, 45, 47, 48, 49, 54, 55, 57, 58, 59, 62, 63, 64, 65, 68, 72, 73,\n",
       "               76, 81])                                                           ,\n",
       "        array([44, 51, 52, 57, 62, 66, 70, 80, 81]), array([16, 64, 81]),\n",
       "        array([11, 25, 49, 64, 81]),\n",
       "        array([ 5,  7,  8, 11, 12, 20, 24, 34, 35, 36, 40, 42, 43, 50, 52, 59, 60,\n",
       "               62, 63, 65, 66, 70, 74, 75, 79, 80, 81])                           ,\n",
       "        array([ 5,  7,  8, 11, 12, 13, 15, 16, 17, 20, 21, 24, 25, 29, 39, 40, 45,\n",
       "               47, 48, 49, 54, 55, 57, 58, 59, 62, 63, 64, 65, 68, 72, 73, 76, 81]),\n",
       "        array([44, 51, 57, 62, 66, 70, 80, 81])], dtype=object),\n",
       " 'legal_moves': array([array([ 0,  5,  7,  8, 11, 12, 16, 19, 20, 21, 22, 24, 34, 35, 36, 37, 40,\n",
       "               41, 42, 43, 45, 47, 50, 52, 57, 58, 59, 60, 62, 63, 65, 66, 68, 70,\n",
       "               71, 72, 74, 75, 77, 79, 80, 81])                                   ,\n",
       "        array([ 5,  7,  8, 11, 12, 13, 15, 16, 17, 20, 21, 24, 25, 29, 39, 40, 45,\n",
       "               47, 48, 49, 54, 55, 57, 58, 59, 62, 63, 64, 65, 68, 72, 73, 76, 81]),\n",
       "        array([44, 51, 57, 62, 66, 70, 80, 81]),\n",
       "        array([16, 47, 55, 56, 57, 65, 74, 81]), array([25, 49, 64, 81]),\n",
       "        array([ 5,  7,  8, 12, 20, 24, 34, 35, 36, 40, 42, 50, 52, 59, 60, 62, 63,\n",
       "               65, 66, 70, 74, 75, 79, 80, 81])                                   ,\n",
       "        array([ 5,  7,  8, 11, 12, 13, 15, 16, 17, 20, 24, 25, 29, 40, 45, 47, 48,\n",
       "               49, 54, 55, 57, 58, 59, 62, 63, 64, 65, 68, 72, 73, 76, 81])       ,\n",
       "        array([44, 57, 62, 66, 70, 80, 81])], dtype=object),\n",
       " 'chosen_move': tensor([[28., 30., 52., 64., 11., 43., 21., 51.]]),\n",
       " 'value': tensor([[-0.0607, -0.0257, -0.0205, -0.0207, -0.0233, -0.0484, -0.0268, -0.0254]]),\n",
       " 'gae': tensor([[0.0392, 0.0392, 0.0392, 0.0408, 0.0394, 0.0392, 0.0392, 0.0392]])}"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "b87ccc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03921694, -0.03921831, -0.03922087, -0.03922635, -0.03923744,\n",
       "       -0.03925991, -0.03930593, -0.03939974, -0.03959131, -0.03998232,\n",
       "       -0.04078025, -0.04240865, -0.0457319 , -0.05251414, -0.06635547,\n",
       "       -0.094603  , -0.15225095, -0.26989996, -0.50999999, -1.        ])"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gae(erm.data.reward, erm.data.value, np.append(erm.data.value[1:],0), 0.98, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "3fc2f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_v = F.smooth_l1_loss(values[:,0], (data['reward'] + gamma*new_values[0]*(1-data['done']))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "d660cbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<SmoothL1LossBackward0>)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "1fd5282e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1., -1., -1., -1., -1., -1.])"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data['reward'] + gamma*new_values[0]*(1-data['done']))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "cc3527af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1., -1., -1., -1., -1., -1.], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "e3dd4cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8])"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data['reward'] + gamma*new_values[0]*(1-data['done'])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "7e6b5b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800]])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['reward'] + gamma*new_values[0]*(1-data['done'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "72e54e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_observation</th>\n",
       "      <th>observation</th>\n",
       "      <th>reward</th>\n",
       "      <th>done</th>\n",
       "      <th>old_legal_moves</th>\n",
       "      <th>legal_moves</th>\n",
       "      <th>chosen_move</th>\n",
       "      <th>value</th>\n",
       "      <th>gae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>862e39d4-6f9c-4bc4-a838-9a1c594a95ab</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[11, 12, 18, 19, 20, 21, 28, 29, 36, 39, 40, 4...</td>\n",
       "      <td>[12, 18, 19, 20, 21, 28, 29, 36, 39, 40, 45, 4...</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.069335</td>\n",
       "      <td>-0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9bc3348b-4070-43ef-a2d5-44617d81011f</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[12, 18, 19, 20, 21, 28, 29, 36, 39, 40, 45, 4...</td>\n",
       "      <td>[12, 18, 19, 20, 28, 29, 36, 39, 40, 45, 46, 4...</td>\n",
       "      <td>65</td>\n",
       "      <td>-0.071543</td>\n",
       "      <td>-0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da7a2bf8-8289-4699-80ad-3a074dbbe4ea</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[12, 18, 19, 20, 28, 29, 36, 39, 40, 45, 46, 4...</td>\n",
       "      <td>[12, 18, 19, 20, 28, 29, 39, 40, 45, 46, 47, 5...</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.077015</td>\n",
       "      <td>-0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7eda99aa-2815-4bb2-932b-16ad460169da</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[12, 18, 19, 20, 28, 29, 39, 40, 45, 46, 47, 5...</td>\n",
       "      <td>[12, 19, 20, 28, 29, 39, 40, 43, 44, 45, 46, 4...</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.080044</td>\n",
       "      <td>-0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1c2ac54-a3fb-49b4-94f5-8e200a5e6b2d</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[12, 19, 20, 28, 29, 39, 40, 43, 44, 45, 46, 4...</td>\n",
       "      <td>[12, 19, 20, 28, 29, 39, 40, 43, 44, 45, 55, 5...</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.090791</td>\n",
       "      <td>-0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3b5350c-0cab-4bb0-9775-db381625d74c</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[12, 19, 20, 28, 29, 39, 40, 43, 44, 45, 55, 5...</td>\n",
       "      <td>[12, 19, 20, 28, 29, 39, 40, 55, 58, 59, 64, 6...</td>\n",
       "      <td>45</td>\n",
       "      <td>-0.079023</td>\n",
       "      <td>-0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbe07421-c362-4fa6-b423-e6f742c648be</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[12, 19, 20, 28, 29, 39, 40, 55, 58, 59, 64, 6...</td>\n",
       "      <td>[12, 19, 20, 29, 39, 40, 55, 58, 59, 64, 67, 7...</td>\n",
       "      <td>74</td>\n",
       "      <td>-0.086739</td>\n",
       "      <td>-0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c9936be4-3731-4128-841a-0c3c6415f698</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[12, 19, 20, 29, 39, 40, 55, 58, 59, 64, 67, 7...</td>\n",
       "      <td>[12, 19, 20, 29, 39, 40, 55, 58, 59, 64, 73, 7...</td>\n",
       "      <td>67</td>\n",
       "      <td>-0.080280</td>\n",
       "      <td>-0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64d810f2-a739-46e7-b059-c96ab9351b6a</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[12, 19, 20, 29, 39, 40, 55, 58, 59, 64, 73, 7...</td>\n",
       "      <td>[12, 19, 20, 29, 39, 40, 55, 58, 59, 75, 77, 81]</td>\n",
       "      <td>73</td>\n",
       "      <td>-0.083239</td>\n",
       "      <td>-0.000391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6dea21b1-ef8c-4d10-bc18-13aec34e8406</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[12, 19, 20, 29, 39, 40, 55, 58, 59, 75, 77, 81]</td>\n",
       "      <td>[12, 18, 20, 27, 29, 39, 40, 55, 59, 75, 77, 81]</td>\n",
       "      <td>58</td>\n",
       "      <td>-0.080218</td>\n",
       "      <td>-0.000798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04dc5f80-92b8-4685-85a5-6b74cc7f5294</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[12, 18, 20, 27, 29, 39, 40, 55, 59, 75, 77, 81]</td>\n",
       "      <td>[12, 20, 29, 55, 59, 75, 77, 81]</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.074773</td>\n",
       "      <td>-0.001628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41c90752-114a-48c1-8980-2bda896e6066</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[12, 20, 29, 55, 59, 75, 77, 81]</td>\n",
       "      <td>[12, 20, 29, 55, 59, 75, 81]</td>\n",
       "      <td>77</td>\n",
       "      <td>-0.076359</td>\n",
       "      <td>-0.003323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590bcdf1-cf09-4760-8e0f-a01c9c67dd79</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[12, 20, 29, 55, 59, 75, 81]</td>\n",
       "      <td>[55, 59, 75, 81]</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.072056</td>\n",
       "      <td>-0.006782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4626c73c-94f5-4a75-8c77-a702854046c3</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[55, 59, 75, 81]</td>\n",
       "      <td>[55, 81]</td>\n",
       "      <td>59</td>\n",
       "      <td>-0.075452</td>\n",
       "      <td>-0.013841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60b21a36-1c40-4258-b3ee-94cdd01f0d14</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[55, 81]</td>\n",
       "      <td>[11, 20, 63, 64, 72, 75, 81]</td>\n",
       "      <td>55</td>\n",
       "      <td>-0.079448</td>\n",
       "      <td>-0.028248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9a2176b5-c273-4436-84d2-33cb3f73cff7</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[11, 20, 63, 64, 72, 75, 81]</td>\n",
       "      <td>[63, 64, 72, 75, 81]</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.093763</td>\n",
       "      <td>-0.057648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6ffb24aa-3eaa-4af1-8832-8d6507623de6</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[63, 64, 72, 75, 81]</td>\n",
       "      <td>[63, 72, 75, 81]</td>\n",
       "      <td>64</td>\n",
       "      <td>-0.097668</td>\n",
       "      <td>-0.117649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01a4bc0c-0e67-45ac-a94d-1274ea5479dd</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[63, 72, 75, 81]</td>\n",
       "      <td>[63, 75, 81]</td>\n",
       "      <td>72</td>\n",
       "      <td>-0.090947</td>\n",
       "      <td>-0.240100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83ec5b50-b547-4ad2-b54a-9c9359a4333e</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[63, 75, 81]</td>\n",
       "      <td>[81]</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.090216</td>\n",
       "      <td>-0.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb4647da-036c-49a8-93bd-386c46adbd4f</th>\n",
       "      <td>[[tensor(1.), tensor(1.), tensor(1.), tensor(1...</td>\n",
       "      <td>[[tensor(-1.), tensor(-1.), tensor(-1.), tenso...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>[81]</td>\n",
       "      <td>[81]</td>\n",
       "      <td>81</td>\n",
       "      <td>-0.089816</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        old_observation  \\\n",
       "862e39d4-6f9c-4bc4-a838-9a1c594a95ab  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "9bc3348b-4070-43ef-a2d5-44617d81011f  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "da7a2bf8-8289-4699-80ad-3a074dbbe4ea  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "7eda99aa-2815-4bb2-932b-16ad460169da  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "f1c2ac54-a3fb-49b4-94f5-8e200a5e6b2d  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "f3b5350c-0cab-4bb0-9775-db381625d74c  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "fbe07421-c362-4fa6-b423-e6f742c648be  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "c9936be4-3731-4128-841a-0c3c6415f698  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "64d810f2-a739-46e7-b059-c96ab9351b6a  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "6dea21b1-ef8c-4d10-bc18-13aec34e8406  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "04dc5f80-92b8-4685-85a5-6b74cc7f5294  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "41c90752-114a-48c1-8980-2bda896e6066  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "590bcdf1-cf09-4760-8e0f-a01c9c67dd79  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "4626c73c-94f5-4a75-8c77-a702854046c3  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "60b21a36-1c40-4258-b3ee-94cdd01f0d14  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "9a2176b5-c273-4436-84d2-33cb3f73cff7  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "6ffb24aa-3eaa-4af1-8832-8d6507623de6  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "01a4bc0c-0e67-45ac-a94d-1274ea5479dd  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "83ec5b50-b547-4ad2-b54a-9c9359a4333e  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "fb4647da-036c-49a8-93bd-386c46adbd4f  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "\n",
       "                                                                            observation  \\\n",
       "862e39d4-6f9c-4bc4-a838-9a1c594a95ab  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "9bc3348b-4070-43ef-a2d5-44617d81011f  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "da7a2bf8-8289-4699-80ad-3a074dbbe4ea  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "7eda99aa-2815-4bb2-932b-16ad460169da  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "f1c2ac54-a3fb-49b4-94f5-8e200a5e6b2d  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "f3b5350c-0cab-4bb0-9775-db381625d74c  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "fbe07421-c362-4fa6-b423-e6f742c648be  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "c9936be4-3731-4128-841a-0c3c6415f698  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "64d810f2-a739-46e7-b059-c96ab9351b6a  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "6dea21b1-ef8c-4d10-bc18-13aec34e8406  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "04dc5f80-92b8-4685-85a5-6b74cc7f5294  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "41c90752-114a-48c1-8980-2bda896e6066  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "590bcdf1-cf09-4760-8e0f-a01c9c67dd79  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "4626c73c-94f5-4a75-8c77-a702854046c3  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "60b21a36-1c40-4258-b3ee-94cdd01f0d14  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "9a2176b5-c273-4436-84d2-33cb3f73cff7  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "6ffb24aa-3eaa-4af1-8832-8d6507623de6  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "01a4bc0c-0e67-45ac-a94d-1274ea5479dd  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "83ec5b50-b547-4ad2-b54a-9c9359a4333e  [[tensor(1.), tensor(1.), tensor(1.), tensor(1...   \n",
       "fb4647da-036c-49a8-93bd-386c46adbd4f  [[tensor(-1.), tensor(-1.), tensor(-1.), tenso...   \n",
       "\n",
       "                                      reward   done  \\\n",
       "862e39d4-6f9c-4bc4-a838-9a1c594a95ab     0.0  False   \n",
       "9bc3348b-4070-43ef-a2d5-44617d81011f     0.0  False   \n",
       "da7a2bf8-8289-4699-80ad-3a074dbbe4ea     0.0  False   \n",
       "7eda99aa-2815-4bb2-932b-16ad460169da     0.0  False   \n",
       "f1c2ac54-a3fb-49b4-94f5-8e200a5e6b2d     0.0  False   \n",
       "f3b5350c-0cab-4bb0-9775-db381625d74c     0.0  False   \n",
       "fbe07421-c362-4fa6-b423-e6f742c648be     0.0  False   \n",
       "c9936be4-3731-4128-841a-0c3c6415f698     0.0  False   \n",
       "64d810f2-a739-46e7-b059-c96ab9351b6a     0.0  False   \n",
       "6dea21b1-ef8c-4d10-bc18-13aec34e8406     0.0  False   \n",
       "04dc5f80-92b8-4685-85a5-6b74cc7f5294     0.0  False   \n",
       "41c90752-114a-48c1-8980-2bda896e6066     0.0  False   \n",
       "590bcdf1-cf09-4760-8e0f-a01c9c67dd79     0.0  False   \n",
       "4626c73c-94f5-4a75-8c77-a702854046c3     0.0  False   \n",
       "60b21a36-1c40-4258-b3ee-94cdd01f0d14     0.0  False   \n",
       "9a2176b5-c273-4436-84d2-33cb3f73cff7     0.0  False   \n",
       "6ffb24aa-3eaa-4af1-8832-8d6507623de6     0.0  False   \n",
       "01a4bc0c-0e67-45ac-a94d-1274ea5479dd     0.0  False   \n",
       "83ec5b50-b547-4ad2-b54a-9c9359a4333e     0.0  False   \n",
       "fb4647da-036c-49a8-93bd-386c46adbd4f    -1.0   True   \n",
       "\n",
       "                                                                        old_legal_moves  \\\n",
       "862e39d4-6f9c-4bc4-a838-9a1c594a95ab  [11, 12, 18, 19, 20, 21, 28, 29, 36, 39, 40, 4...   \n",
       "9bc3348b-4070-43ef-a2d5-44617d81011f  [12, 18, 19, 20, 21, 28, 29, 36, 39, 40, 45, 4...   \n",
       "da7a2bf8-8289-4699-80ad-3a074dbbe4ea  [12, 18, 19, 20, 28, 29, 36, 39, 40, 45, 46, 4...   \n",
       "7eda99aa-2815-4bb2-932b-16ad460169da  [12, 18, 19, 20, 28, 29, 39, 40, 45, 46, 47, 5...   \n",
       "f1c2ac54-a3fb-49b4-94f5-8e200a5e6b2d  [12, 19, 20, 28, 29, 39, 40, 43, 44, 45, 46, 4...   \n",
       "f3b5350c-0cab-4bb0-9775-db381625d74c  [12, 19, 20, 28, 29, 39, 40, 43, 44, 45, 55, 5...   \n",
       "fbe07421-c362-4fa6-b423-e6f742c648be  [12, 19, 20, 28, 29, 39, 40, 55, 58, 59, 64, 6...   \n",
       "c9936be4-3731-4128-841a-0c3c6415f698  [12, 19, 20, 29, 39, 40, 55, 58, 59, 64, 67, 7...   \n",
       "64d810f2-a739-46e7-b059-c96ab9351b6a  [12, 19, 20, 29, 39, 40, 55, 58, 59, 64, 73, 7...   \n",
       "6dea21b1-ef8c-4d10-bc18-13aec34e8406   [12, 19, 20, 29, 39, 40, 55, 58, 59, 75, 77, 81]   \n",
       "04dc5f80-92b8-4685-85a5-6b74cc7f5294   [12, 18, 20, 27, 29, 39, 40, 55, 59, 75, 77, 81]   \n",
       "41c90752-114a-48c1-8980-2bda896e6066                   [12, 20, 29, 55, 59, 75, 77, 81]   \n",
       "590bcdf1-cf09-4760-8e0f-a01c9c67dd79                       [12, 20, 29, 55, 59, 75, 81]   \n",
       "4626c73c-94f5-4a75-8c77-a702854046c3                                   [55, 59, 75, 81]   \n",
       "60b21a36-1c40-4258-b3ee-94cdd01f0d14                                           [55, 81]   \n",
       "9a2176b5-c273-4436-84d2-33cb3f73cff7                       [11, 20, 63, 64, 72, 75, 81]   \n",
       "6ffb24aa-3eaa-4af1-8832-8d6507623de6                               [63, 64, 72, 75, 81]   \n",
       "01a4bc0c-0e67-45ac-a94d-1274ea5479dd                                   [63, 72, 75, 81]   \n",
       "83ec5b50-b547-4ad2-b54a-9c9359a4333e                                       [63, 75, 81]   \n",
       "fb4647da-036c-49a8-93bd-386c46adbd4f                                               [81]   \n",
       "\n",
       "                                                                            legal_moves  \\\n",
       "862e39d4-6f9c-4bc4-a838-9a1c594a95ab  [12, 18, 19, 20, 21, 28, 29, 36, 39, 40, 45, 4...   \n",
       "9bc3348b-4070-43ef-a2d5-44617d81011f  [12, 18, 19, 20, 28, 29, 36, 39, 40, 45, 46, 4...   \n",
       "da7a2bf8-8289-4699-80ad-3a074dbbe4ea  [12, 18, 19, 20, 28, 29, 39, 40, 45, 46, 47, 5...   \n",
       "7eda99aa-2815-4bb2-932b-16ad460169da  [12, 19, 20, 28, 29, 39, 40, 43, 44, 45, 46, 4...   \n",
       "f1c2ac54-a3fb-49b4-94f5-8e200a5e6b2d  [12, 19, 20, 28, 29, 39, 40, 43, 44, 45, 55, 5...   \n",
       "f3b5350c-0cab-4bb0-9775-db381625d74c  [12, 19, 20, 28, 29, 39, 40, 55, 58, 59, 64, 6...   \n",
       "fbe07421-c362-4fa6-b423-e6f742c648be  [12, 19, 20, 29, 39, 40, 55, 58, 59, 64, 67, 7...   \n",
       "c9936be4-3731-4128-841a-0c3c6415f698  [12, 19, 20, 29, 39, 40, 55, 58, 59, 64, 73, 7...   \n",
       "64d810f2-a739-46e7-b059-c96ab9351b6a   [12, 19, 20, 29, 39, 40, 55, 58, 59, 75, 77, 81]   \n",
       "6dea21b1-ef8c-4d10-bc18-13aec34e8406   [12, 18, 20, 27, 29, 39, 40, 55, 59, 75, 77, 81]   \n",
       "04dc5f80-92b8-4685-85a5-6b74cc7f5294                   [12, 20, 29, 55, 59, 75, 77, 81]   \n",
       "41c90752-114a-48c1-8980-2bda896e6066                       [12, 20, 29, 55, 59, 75, 81]   \n",
       "590bcdf1-cf09-4760-8e0f-a01c9c67dd79                                   [55, 59, 75, 81]   \n",
       "4626c73c-94f5-4a75-8c77-a702854046c3                                           [55, 81]   \n",
       "60b21a36-1c40-4258-b3ee-94cdd01f0d14                       [11, 20, 63, 64, 72, 75, 81]   \n",
       "9a2176b5-c273-4436-84d2-33cb3f73cff7                               [63, 64, 72, 75, 81]   \n",
       "6ffb24aa-3eaa-4af1-8832-8d6507623de6                                   [63, 72, 75, 81]   \n",
       "01a4bc0c-0e67-45ac-a94d-1274ea5479dd                                       [63, 75, 81]   \n",
       "83ec5b50-b547-4ad2-b54a-9c9359a4333e                                               [81]   \n",
       "fb4647da-036c-49a8-93bd-386c46adbd4f                                               [81]   \n",
       "\n",
       "                                     chosen_move     value       gae  \n",
       "862e39d4-6f9c-4bc4-a838-9a1c594a95ab          11 -0.069335 -0.000001  \n",
       "9bc3348b-4070-43ef-a2d5-44617d81011f          65 -0.071543 -0.000003  \n",
       "da7a2bf8-8289-4699-80ad-3a074dbbe4ea          54 -0.077015 -0.000005  \n",
       "7eda99aa-2815-4bb2-932b-16ad460169da          18 -0.080044 -0.000011  \n",
       "f1c2ac54-a3fb-49b4-94f5-8e200a5e6b2d          46 -0.090791 -0.000023  \n",
       "f3b5350c-0cab-4bb0-9775-db381625d74c          45 -0.079023 -0.000046  \n",
       "fbe07421-c362-4fa6-b423-e6f742c648be          74 -0.086739 -0.000094  \n",
       "c9936be4-3731-4128-841a-0c3c6415f698          67 -0.080280 -0.000192  \n",
       "64d810f2-a739-46e7-b059-c96ab9351b6a          73 -0.083239 -0.000391  \n",
       "6dea21b1-ef8c-4d10-bc18-13aec34e8406          58 -0.080218 -0.000798  \n",
       "04dc5f80-92b8-4685-85a5-6b74cc7f5294          18 -0.074773 -0.001628  \n",
       "41c90752-114a-48c1-8980-2bda896e6066          77 -0.076359 -0.003323  \n",
       "590bcdf1-cf09-4760-8e0f-a01c9c67dd79          20 -0.072056 -0.006782  \n",
       "4626c73c-94f5-4a75-8c77-a702854046c3          59 -0.075452 -0.013841  \n",
       "60b21a36-1c40-4258-b3ee-94cdd01f0d14          55 -0.079448 -0.028248  \n",
       "9a2176b5-c273-4436-84d2-33cb3f73cff7          11 -0.093763 -0.057648  \n",
       "6ffb24aa-3eaa-4af1-8832-8d6507623de6          64 -0.097668 -0.117649  \n",
       "01a4bc0c-0e67-45ac-a94d-1274ea5479dd          72 -0.090947 -0.240100  \n",
       "83ec5b50-b547-4ad2-b54a-9c9359a4333e          75 -0.090216 -0.490000  \n",
       "fb4647da-036c-49a8-93bd-386c46adbd4f          81 -0.089816 -1.000000  "
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erm.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "d933e210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "c15fdadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(erm.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "a69e2a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(erm.current_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bebe02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "5edcf787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['done']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "a1f57af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800],\n",
       "        [-0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800],\n",
       "        [-0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800],\n",
       "        [-0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800],\n",
       "        [-0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800],\n",
       "        [-0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800],\n",
       "        [-0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800],\n",
       "        [-0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800, -0.9800]])"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['reward'] + gamma*new_values*(1-data['done'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "7c4ed6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "af110053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(gamma*new_values*(1-data['done'])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "e2fb7b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "4e779543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['reward'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "90617146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.007821455597877502,\n",
       " 0.00784947071224451,\n",
       " 0.007877429947257042,\n",
       " 0.00790549349039793,\n",
       " 3.0834832191467285,\n",
       " 0.007961610332131386,\n",
       " 0.007989715784788132,\n",
       " 0.00801781751215458,\n",
       " 0.008046022616326809,\n",
       " 0.008074169978499413,\n",
       " 0.008102420717477798,\n",
       " 0.008130612783133984,\n",
       " 0.008158906362950802,\n",
       " 0.008187196217477322,\n",
       " 0.008215482346713543,\n",
       " 0.008243869990110397,\n",
       " 0.00827225111424923,\n",
       " 0.008300629444420338,\n",
       " 0.008329054340720177,\n",
       " 0.008357472717761993,\n",
       " 2.9465503692626953,\n",
       " 0.008414402604103088,\n",
       " 0.008442913182079792,\n",
       " 0.008471472188830376,\n",
       " 0.008500022813677788,\n",
       " 0.008528566919267178,\n",
       " 0.008557159453630447,\n",
       " 0.008585800416767597,\n",
       " 0.008614432066679,\n",
       " 0.008643057197332382,\n",
       " 0.008671729825437069,\n",
       " 0.008700449950993061,\n",
       " 0.008729161694645882,\n",
       " 0.008757920935750008,\n",
       " 0.008786670863628387,\n",
       " 0.008815469220280647,\n",
       " 0.008844312280416489,\n",
       " 0.008873148821294308,\n",
       " 0.00890197604894638,\n",
       " 0.008930847980082035,\n",
       " 0.00895976647734642,\n",
       " 0.008988678455352783,\n",
       " 0.009017633274197578,\n",
       " 0.009046580642461777,\n",
       " 0.00907551683485508,\n",
       " 0.00910455547273159,\n",
       " 0.00913358386605978,\n",
       " 2.7267494201660156,\n",
       " 0.009191608987748623,\n",
       " 0.00922071747481823,\n",
       " 0.009249759837985039,\n",
       " 0.009278903715312481,\n",
       " 0.009308034554123878,\n",
       " 0.00933721475303173,\n",
       " 0.009366380050778389,\n",
       " 0.009395534172654152,\n",
       " 0.009424732998013496,\n",
       " 0.009453978389501572,\n",
       " 0.009483208879828453,\n",
       " 2.633476734161377,\n",
       " 0.009541808627545834,\n",
       " 0.009571116417646408,\n",
       " 0.009600413031876087,\n",
       " 0.009629751555621624,\n",
       " 0.009659078903496265,\n",
       " 0.009688506834208965,\n",
       " 0.00971786305308342,\n",
       " 0.00974726490676403,\n",
       " 0.009776711463928223,\n",
       " 0.009806143119931221,\n",
       " 0.009835617616772652,\n",
       " 0.009865077212452888,\n",
       " 0.009894581511616707,\n",
       " 0.009924071840941906,\n",
       " 0.009953541681170464,\n",
       " 0.009983060881495476,\n",
       " 0.010012621060013771,\n",
       " 0.010042165406048298,\n",
       " 0.010071754455566406,\n",
       " 0.010101325809955597,\n",
       " 0.01013088133186102,\n",
       " 2.46934175491333,\n",
       " 0.010190061293542385,\n",
       " 0.010219684801995754,\n",
       " 0.010249353013932705,\n",
       " 0.010279002599418163,\n",
       " 0.01030869409441948,\n",
       " 2.4261200428009033,\n",
       " 0.010368026793003082,\n",
       " 0.01039772666990757,\n",
       " 0.010427528992295265,\n",
       " 0.010457254014909267,\n",
       " 0.010487018153071404,\n",
       " 0.010516704060137272,\n",
       " 0.010546553879976273,\n",
       " 0.010576324537396431,\n",
       " 0.010606135241687298,\n",
       " 0.010635990649461746,\n",
       " 0.010665763169527054,\n",
       " 0.010695699602365494,\n",
       " 0.010725433006882668,\n",
       " 0.010755331255495548,\n",
       " 0.010785147547721863,\n",
       " 0.010815126821398735,\n",
       " 0.010845025070011616,\n",
       " 0.010874839499592781,\n",
       " 0.010904817841947079,\n",
       " 0.010934717953205109,\n",
       " 0.010964654386043549,\n",
       " 0.010994510725140572,\n",
       " 0.011024528183043003,\n",
       " 0.011054464615881443,\n",
       " 23.30930519104004,\n",
       " 0.011114329099655151,\n",
       " 0.011144260875880718,\n",
       " 0.011174232698976994,\n",
       " 0.011204244568943977,\n",
       " 0.011234295554459095,\n",
       " 0.011264260858297348,\n",
       " 0.011294394731521606,\n",
       " 0.011324310675263405,\n",
       " 0.011354397051036358,\n",
       " 0.011384520679712296,\n",
       " 0.011414560489356518,\n",
       " 0.011444635689258575,\n",
       " 0.01147475466132164,\n",
       " 0.011504782363772392,\n",
       " 0.011534850113093853,\n",
       " 0.011564955115318298,\n",
       " 0.011595102958381176,\n",
       " 0.011625288054347038,\n",
       " 0.011655384674668312,\n",
       " 0.011685519479215145,\n",
       " 0.011715693399310112,\n",
       " 0.011745905503630638,\n",
       " 0.01177603006362915,\n",
       " 0.011806189082562923,\n",
       " 0.011836388148367405,\n",
       " 0.011866495944559574,\n",
       " 0.011896774172782898,\n",
       " 0.011926958337426186,\n",
       " 0.011957180686295033,\n",
       " 0.011987309902906418,\n",
       " 0.012017608620226383,\n",
       " 0.012047817930579185,\n",
       " 0.012078061699867249,\n",
       " 0.012108342722058296,\n",
       " 0.012138533405959606,\n",
       " 0.0121687613427639,\n",
       " 0.01219902466982603,\n",
       " 0.01222932804375887,\n",
       " 0.012259534560143948,\n",
       " 24.169471740722656,\n",
       " 0.012320062145590782,\n",
       " 0.012350380420684814,\n",
       " 24.233152389526367,\n",
       " 0.012410866096615791,\n",
       " 0.012441163882613182,\n",
       " 0.012471497058868408,\n",
       " 0.012501733377575874,\n",
       " 0.012532142922282219,\n",
       " 0.012562322430312634,\n",
       " 0.012592669576406479,\n",
       " 0.012623054906725883,\n",
       " 0.012653343379497528,\n",
       " 1.9201581478118896,\n",
       " 0.01271389052271843,\n",
       " 0.012744287960231304,\n",
       " 0.012774585746228695,\n",
       " 0.012804917991161346,\n",
       " 0.012835153378546238,\n",
       " 0.012865561060607433,\n",
       " 0.012895865365862846,\n",
       " 0.012926071882247925,\n",
       " 0.012956447899341583,\n",
       " 0.012986726127564907,\n",
       " 0.013017036020755768,\n",
       " 0.013047385029494762,\n",
       " 0.01307763159275055,\n",
       " 0.013107914477586746,\n",
       " 0.013138229958713055,\n",
       " 0.01316844392567873,\n",
       " 0.01319882832467556,\n",
       " 0.013229114934802055,\n",
       " 0.013259299099445343,\n",
       " 0.013289649039506912,\n",
       " 0.013319900259375572,\n",
       " 0.013350185006856918,\n",
       " 1.7897416353225708,\n",
       " 0.013410859741270542,\n",
       " 0.013441110961139202,\n",
       " 0.013471533544361591,\n",
       " 0.013501850888133049,\n",
       " 0.01353206392377615,\n",
       " 0.013562452979385853,\n",
       " 0.013592731207609177,\n",
       " 0.01362304762005806,\n",
       " 0.013653397560119629,\n",
       " 0.013683641329407692,\n",
       " 0.013713918626308441,\n",
       " 0.013744227588176727,\n",
       " 0.013774571940302849,\n",
       " 0.01380480919033289,\n",
       " 1.7089494466781616,\n",
       " 0.01386538241058588,\n",
       " 25.274452209472656,\n",
       " 0.013925949111580849,\n",
       " 0.01395621057599783,\n",
       " 0.013986507430672646,\n",
       " 0.0140168322250247,\n",
       " 0.014047052711248398,\n",
       " 0.014077304862439632,\n",
       " 0.014107588678598404,\n",
       " 0.014137904159724712,\n",
       " 0.014168115332722664,\n",
       " 0.01419835351407528,\n",
       " 0.014228622429072857,\n",
       " 0.01425892859697342,\n",
       " 0.014289121143519878,\n",
       " 25.55912208557129,\n",
       " 0.014349606819450855,\n",
       " 1.616294026374817,\n",
       " 0.01441007386893034,\n",
       " 0.014440283179283142,\n",
       " 0.01447052601724863,\n",
       " 0.014500800520181656,\n",
       " 0.014530960470438004,\n",
       " 0.014561151154339314,\n",
       " 0.014591378159821033,\n",
       " 0.014621486887335777,\n",
       " 0.014651629142463207,\n",
       " 0.014681803993880749,\n",
       " 0.014712008647620678,\n",
       " 0.01474209874868393,\n",
       " 0.014772220514714718,\n",
       " 0.014802372083067894,\n",
       " 0.014832554385066032,\n",
       " 0.014862623065710068,\n",
       " 0.01489287056028843,\n",
       " 0.01492299884557724,\n",
       " 0.014953011646866798,\n",
       " 25.999868392944336,\n",
       " 0.015013276599347591,\n",
       " 0.015043381601572037,\n",
       " 0.015073517337441444,\n",
       " 0.01510353572666645,\n",
       " 0.01513358112424612,\n",
       " 0.015163661912083626,\n",
       " 0.015193767845630646,\n",
       " 0.015223756432533264,\n",
       " 0.015253778547048569,\n",
       " 0.015283680520951748,\n",
       " 0.015313760377466679,\n",
       " 0.015343723818659782,\n",
       " 0.0153737124055624,\n",
       " 0.01540373358875513,\n",
       " 0.015433631837368011,\n",
       " 0.015463710762560368,\n",
       " 26.33473777770996,\n",
       " 0.015523658134043217,\n",
       " 0.015553527511656284,\n",
       " 0.015583423897624016,\n",
       " 0.01561335101723671,\n",
       " 0.015643304213881493,\n",
       " 0.015673289075493813,\n",
       " 0.015703149139881134,\n",
       " 0.015733040869235992,\n",
       " 0.01576296053826809,\n",
       " 0.015792910009622574,\n",
       " 0.01582273468375206,\n",
       " 0.015852587297558784,\n",
       " 0.015882471576333046,\n",
       " 0.015912381932139397,\n",
       " 0.015942318364977837,\n",
       " 0.015972137451171875,\n",
       " 1.3649979829788208,\n",
       " 0.01603185385465622,\n",
       " 0.016061604022979736,\n",
       " 0.01609152927994728,\n",
       " 0.016121333464980125,\n",
       " 0.01615101285278797,\n",
       " 0.016180872917175293,\n",
       " 0.016210608184337616,\n",
       " 0.016240371391177177,\n",
       " 0.016270160675048828,\n",
       " 0.01629982329905033,\n",
       " 0.016329515725374222,\n",
       " 0.016359083354473114,\n",
       " 0.016388827934861183,\n",
       " 0.016418447718024254,\n",
       " 0.016448095440864563,\n",
       " 0.016477767378091812,\n",
       " 0.016507312655448914,\n",
       " 0.016536887735128403,\n",
       " 0.016566487029194832,\n",
       " 0.016595959663391113,\n",
       " 0.01662561297416687,\n",
       " 0.01665513589978218,\n",
       " 0.01668468862771988,\n",
       " 27.121967315673828,\n",
       " 0.016743717715144157,\n",
       " 0.016773344948887825,\n",
       " 0.016802847385406494,\n",
       " 0.016832374036312103,\n",
       " 0.016861774027347565,\n",
       " 0.016891352832317352,\n",
       " 0.016920803114771843,\n",
       " 0.016950275748968124,\n",
       " 0.016979780048131943,\n",
       " 0.017009148374199867,\n",
       " 0.01703854836523533,\n",
       " 0.01706796884536743,\n",
       " 0.017097419127821922,\n",
       " 0.017126889899373055,\n",
       " 0.017156077548861504,\n",
       " 0.01718544401228428,\n",
       " 0.017214836552739143,\n",
       " 0.017244096845388412,\n",
       " 0.01727338135242462,\n",
       " 0.01730269193649292,\n",
       " 0.017332028597593307,\n",
       " 0.017361389473080635,\n",
       " 0.017390616238117218,\n",
       " 0.01741986908018589,\n",
       " 0.01744914799928665,\n",
       " 0.017478449270129204,\n",
       " 0.01750761643052101,\n",
       " 0.017536811530590057,\n",
       " 0.017566028982400894,\n",
       " 0.01759526878595352,\n",
       " 0.017624376341700554,\n",
       " 0.01765366643667221,\n",
       " 0.017682820558547974,\n",
       " 0.017712000757455826,\n",
       " 0.017741044983267784,\n",
       " 0.01777011528611183,\n",
       " 0.017799366265535355,\n",
       " 0.01782832480967045,\n",
       " 0.017857464030385017,\n",
       " 0.017886469140648842,\n",
       " 0.017915496602654457,\n",
       " 0.01794455014169216,\n",
       " 27.916114807128906,\n",
       " 0.018002402037382126,\n",
       " 0.018031366169452667,\n",
       " 0.0180603489279747,\n",
       " 0.01808919943869114,\n",
       " 0.01811807043850422,\n",
       " 0.01814696192741394,\n",
       " 0.01817587949335575,\n",
       " 1.0750737190246582,\n",
       " 0.018233463168144226,\n",
       " 0.018262287601828575,\n",
       " 0.018291138112545013,\n",
       " 0.01831984519958496,\n",
       " 0.01834857650101185,\n",
       " 0.018377330154180527,\n",
       " 0.018405945971608162,\n",
       " 0.01843474805355072,\n",
       " 0.01846340484917164,\n",
       " 0.018492087721824646,\n",
       " 0.018520791083574295,\n",
       " 0.018549354746937752,\n",
       " 0.01857794262468815,\n",
       " 0.018606549128890038,\n",
       " 0.018635177984833717,\n",
       " 0.018663667142391205,\n",
       " 0.018692180514335632,\n",
       " 28.37942123413086,\n",
       " 0.018749265000224113,\n",
       " 0.01877767965197563,\n",
       " 0.018806112930178642,\n",
       " 0.018834570422768593,\n",
       " 0.018863048404455185,\n",
       " 0.01889154687523842,\n",
       " 0.01891990378499031,\n",
       " 0.018948279321193695,\n",
       " 0.01897667720913887,\n",
       " 0.019005099311470985,\n",
       " 0.01903337612748146,\n",
       " 0.019061675295233727,\n",
       " 0.019089993089437485,\n",
       " 0.019118335098028183,\n",
       " 0.01914653182029724,\n",
       " 0.01917474903166294,\n",
       " 0.019202984869480133,\n",
       " 0.019231244921684265,\n",
       " 0.019259359687566757,\n",
       " 0.019287491217255592,\n",
       " 0.019315646961331367,\n",
       " 0.019343821331858635,\n",
       " 0.01937185227870941,\n",
       " 0.01940007135272026,\n",
       " 0.01942814141511917,\n",
       " 0.019456231966614723,\n",
       " 0.019484177231788635,\n",
       " 0.01951214112341404,\n",
       " 0.019540127366781235,\n",
       " 0.019568128511309624,\n",
       " 0.0195961594581604,\n",
       " 0.01962403580546379,\n",
       " 0.019652100279927254,\n",
       " 0.019680019468069077,\n",
       " 0.01970795914530754,\n",
       " 0.019735747948288918,\n",
       " 0.019763723015785217,\n",
       " 0.019791552796959877,\n",
       " 0.01981939934194088,\n",
       " 0.01984727382659912,\n",
       " 0.019874991849064827,\n",
       " 0.019902901723980904,\n",
       " 0.019930658861994743,\n",
       " 0.019958272576332092,\n",
       " 0.019986066967248917,\n",
       " 0.0200137160718441,\n",
       " 0.02004138007760048,\n",
       " 0.020069068297743797,\n",
       " 0.020096775144338608,\n",
       " 0.02012449875473976,\n",
       " 0.020152071490883827,\n",
       " 0.020179666578769684,\n",
       " 0.020207108929753304,\n",
       " 0.020234739407896996,\n",
       " 0.02026222087442875,\n",
       " 0.020289717242121696,\n",
       " 0.020317066460847855,\n",
       " 0.020344603806734085,\n",
       " 0.02037198841571808,\n",
       " 0.020399393513798714,\n",
       " 0.020426642149686813,\n",
       " 0.8301534652709961,\n",
       " 0.020481368526816368,\n",
       " 0.020508674904704094,\n",
       " 0.020535998046398163,\n",
       " 0.819424033164978,\n",
       " 0.020590532571077347,\n",
       " 0.020617742091417313,\n",
       " 0.020644964650273323,\n",
       " 0.020672038197517395,\n",
       " 0.02069929614663124,\n",
       " 0.020726403221488,\n",
       " 0.02075352892279625,\n",
       " 0.020780673250555992,\n",
       " 0.02080783061683178,\n",
       " 0.02083483710885048,\n",
       " 0.0208620335906744,\n",
       " 0.020889073610305786,\n",
       " 0.020915962755680084]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "36deef12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.999997615814209,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.999997615814209,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -21.799999237060547,\n",
       " -1.999997615814209,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.999997615814209,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.7999982833862305,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.7999982833862305,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672,\n",
       " -1.9999980926513672]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "25353bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-16.35268211364746,\n",
       " -16.882858276367188,\n",
       " -19.37784767150879,\n",
       " -14.741109848022461,\n",
       " -20.701602935791016,\n",
       " -15.53093433380127,\n",
       " -16.250961303710938,\n",
       " -13.0906400680542,\n",
       " -19.765714645385742,\n",
       " -14.130338668823242,\n",
       " -18.23744773864746,\n",
       " -18.990041732788086,\n",
       " -21.608858108520508,\n",
       " -20.79874038696289,\n",
       " -23.741863250732422,\n",
       " -21.764177322387695,\n",
       " -23.284482955932617,\n",
       " -28.183473587036133,\n",
       " -41.98383331298828,\n",
       " -61.31343460083008,\n",
       " -55.30613327026367,\n",
       " -89.18364715576172,\n",
       " -120.94459533691406,\n",
       " -85.09255981445312,\n",
       " -124.34806823730469,\n",
       " -152.19947814941406,\n",
       " -172.34365844726562,\n",
       " -261.9233093261719,\n",
       " -226.24478149414062,\n",
       " -253.68310546875,\n",
       " -203.94873046875,\n",
       " -317.4092712402344,\n",
       " -290.2842102050781,\n",
       " -291.5194396972656,\n",
       " -372.82769775390625,\n",
       " -446.91717529296875,\n",
       " -379.376220703125,\n",
       " -513.4480590820312,\n",
       " -523.9698486328125,\n",
       " -675.8705444335938,\n",
       " -847.7994995117188,\n",
       " -762.2334594726562,\n",
       " -813.22265625,\n",
       " -1186.1192626953125,\n",
       " -1452.66064453125,\n",
       " -1119.3922119140625,\n",
       " -1705.62890625,\n",
       " -1443.546142578125,\n",
       " -1778.3548583984375,\n",
       " -2247.6376953125,\n",
       " -inf]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "4233ad86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "93bcc23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 51, 69, 81])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legal_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "6b5c1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, value = agzb(rearrange(observation, 'w h -> 1 w h'), legal_moves = [legal_moves])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "3db895bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
       "        grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[nan]], grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "f27ae197",
   "metadata": {},
   "outputs": [],
   "source": [
    "illegal = lambda legal: [move not in legal for move in range(82)]\n",
    "mask = torch.stack([torch.as_tensor(illegal(lm)) for lm in [legal_moves]])\n",
    "mask[[len(lm) != 1 for lm in [legal_moves]], 81] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "592d8e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = agzb.stem(rearrange(old_observation, 'w h -> 1 w h'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "2a46be3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484a4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "        illegal = lambda legal: [move not in legal for move in range(82)]\n",
    "        mask = torch.stack([torch.as_tensor(illegal(lm)) for lm in legal_moves])\n",
    "        # remove option for pass, unless only move:\n",
    "        mask[[len(lm) != 1 for lm in legal_moves], 81] = 0\n",
    "        x = self.stem(x)\n",
    "        x1 = self.tower1(x)\n",
    "        x1 = x1.masked_fill(mask, -torch.inf)\n",
    "        x1 = F.softmax(x1, dim=-1)\n",
    "        x2 = self.tower2(x)\n",
    "        return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "127e7768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  8, 36, 49, 62, 63, 66, 70, 74, 77, 81])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legal_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "d0fc802e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
