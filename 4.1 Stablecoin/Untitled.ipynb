{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = torch.cumsum(torch.ones(10), dim=-1)\n",
    "successor_value_estimates = torch.cumsum(torch.ones(10)*2, dim=-1)\n",
    "gamma = 0.99\n",
    "n = 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "discounted_succ_values = successor_value_estimates[n:]\n",
    "discounted_succ_values = torch.cat([discounted_succ_values, torch.ones(n)*discounted_succ_values[-1]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 12., 14., 16., 18., 20., 20., 20., 20., 20.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discounted_succ_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 12., 14., 16., 18., 20.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discounted_succ_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([1., 2., 3., 4.])\n",
      "torch.Size([4]) torch.Size([4])\n",
      "1 tensor([2., 3., 4., 5.])\n",
      "torch.Size([4]) torch.Size([4])\n",
      "2 tensor([3., 4., 5., 6.])\n",
      "torch.Size([4]) torch.Size([4])\n",
      "3 tensor([4., 5., 6., 7.])\n",
      "torch.Size([4]) torch.Size([4])\n",
      "4 tensor([5., 6., 7., 8.])\n",
      "torch.Size([4]) torch.Size([4])\n",
      "5 tensor([6., 7., 8., 9.])\n",
      "torch.Size([4]) torch.Size([4])\n",
      "6 tensor([ 7.,  8.,  9., 10.])\n",
      "torch.Size([4]) torch.Size([4])\n",
      "7 tensor([ 8.,  9., 10.])\n",
      "torch.Size([3]) torch.Size([3])\n",
      "8 tensor([ 9., 10.])\n",
      "torch.Size([2]) torch.Size([2])\n",
      "9 tensor([10.])\n",
      "torch.Size([1]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "n = 4\n",
    "discounted_rewards = []\n",
    "len_sequence = len(rewards)\n",
    "for idx in range(len_sequence):\n",
    "    n = min(len_sequence - idx, n)\n",
    "    terms_to_discount = rewards[idx:idx+n]\n",
    "    discount_factors = torch.as_tensor([gamma**i for i in range(n)], dtype=torch.float32)\n",
    "    discounted_reward = terms_to_discount * discount_factors + gamma**(n+1)+successor_value_estimates[idx]\n",
    "    discounted_rewards.append(discounted_reward)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 2.,  3.,  4.,  5.],\n",
       "        [ 3.,  4.,  5.,  6.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 6.,  7.,  8.,  9.],\n",
       "        [ 7.,  8.,  9., 10.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards.unfold(-1, 4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards.unfold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [0., 1., 1.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(torch.ones(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards + gamma*rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: WRITE THIS FUNCTION\n",
    "def calculate_n_step_return(\n",
    "    rewards: torch.Tensor,\n",
    "    successor_value_estimates: torch.Tensor,\n",
    "    n: int,\n",
    "    gamma: float,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculate the n-step return for each timestep in the episode.\n",
    "\n",
    "    n-step return = r_{t+1} + gamma * r_{t+2} + ... + gamma^{n-1} * r_{t+n} + gamma^n * V(s_{t+n})\n",
    "    \"\"\"\n",
    "    \n",
    "    discounted_rewards = []\n",
    "    len_sequence = len(rewards)\n",
    "    for idx in range(len_sequence):\n",
    "        n = min(len_sequence - idx, n)\n",
    "        terms_to_discount = rewards[idx:idx+n]\n",
    "        discount_factors = torch.as_tensor([gamma**i for i in range(n)], dtype=torch.float32)\n",
    "        discounted_reward = (terms_to_discount * discount_factors).sum() + gamma**(n+1)+successor_value_estimates[idx]\n",
    "        discounted_rewards.append(discounted_reward)\n",
    "    return torch.as_tensor(discounted_rewards, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tensor(63.7591)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([63.7591, 63.3931, 63.0233, 62.6498, 62.2725, 61.8914, 61.5065, 61.1177,\n",
       "        60.7249, 60.3282, 59.9275, 59.5227, 59.1139, 58.7009, 58.2837, 57.8623,\n",
       "        57.4367, 57.0068, 56.5725, 56.1338, 55.6907, 55.2432, 54.7911, 54.3344,\n",
       "        53.8731, 53.4072, 52.9366, 52.4612, 51.9810, 51.4960, 51.0060, 50.5111,\n",
       "        50.0112, 49.5063, 48.9963, 48.4811, 47.9607, 47.4350, 46.9041, 46.3678,\n",
       "        45.8260, 45.2788, 44.7261, 44.1677, 43.6038, 43.0341, 42.4587, 41.8775,\n",
       "        41.2904, 40.6974, 40.0984, 39.4933, 38.8821, 38.2648, 37.6412, 37.0113,\n",
       "        36.3750, 35.7323, 35.0832, 34.4275, 33.7651, 33.0961, 32.4203, 31.7376,\n",
       "        31.0481, 30.3516, 29.6481, 28.9375, 28.2197, 27.4946, 26.7623, 26.0225,\n",
       "        25.2752, 24.5204, 23.7580, 22.9879, 22.2100, 21.4243, 20.6306, 19.8288,\n",
       "        19.0190, 18.2010, 17.3748, 16.5402, 15.6972, 14.8456, 13.9855, 13.1166,\n",
       "        12.2390, 11.3526, 10.4571,  9.5527,  8.6390,  7.7162,  6.7841,  5.8425,\n",
       "         4.8914,  3.9307,  2.9603,  1.9801])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = torch.ones(100)\n",
    "successor_value_estimates = torch.zeros(100)\n",
    "n = 120\n",
    "gamma = 0.99\n",
    "\n",
    "calculate_n_step_return(rewards, \n",
    "                        successor_value_estimates, \n",
    "                        n,\n",
    "                        gamma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv38",
   "language": "python",
   "name": "cv38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
