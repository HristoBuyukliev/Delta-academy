{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "0a8099c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from check_submission import check_submission\n",
    "from game_mechanics import (\n",
    "    OthelloEnv,\n",
    "    choose_move_randomly,\n",
    "    load_network,\n",
    "    play_othello_game,\n",
    "    save_network,\n",
    "    get_legal_moves\n",
    ")\n",
    "\n",
    "from einops.layers.torch import Rearrange\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm_notebook\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ad646d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting game. Player -1 has first move\n",
      " [['*' '*' '*' '*' '*' '*']\n",
      " ['*' '*' '*' '*' '*' '*']\n",
      " ['*' '*' 'X' 'O' '*' '*']\n",
      " ['*' '*' 'O' 'X' '*' '*']\n",
      " ['*' '*' '*' '*' '*' '*']\n",
      " ['*' '*' '*' '*' '*' '*']]\n",
      "\n",
      "Player -1 places counter at row 4, column 3\n",
      "[['*' '*' '*' '*' '*' '*']\n",
      " ['*' '*' '*' '*' '*' '*']\n",
      " ['*' '*' 'X' 'O' '*' '*']\n",
      " ['*' '*' 'O' 'O' '*' '*']\n",
      " ['*' '*' '*' 'O' '*' '*']\n",
      " ['*' '*' '*' '*' '*' '*']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = OthelloEnv()\n",
    "state, reward, done, info = env.reset(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "f3504afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OthelloNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OthelloNet, self).__init__()\n",
    "        hidden = 20 \n",
    "        # stride 1\n",
    "        self.conv1 = nn.Conv2d(1,hidden, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(hidden*2,hidden, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(hidden*2,1, kernel_size=1, padding=0)\n",
    "        \n",
    "        # stride 2\n",
    "        self.conv1_s2 = nn.Conv2d(1,hidden, kernel_size=3, padding=2,dilation=2)\n",
    "        self.conv2_s2 = nn.Conv2d(hidden*2,hidden, kernel_size=3, padding=2,dilation=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_1a = self.conv1(x)\n",
    "        x_1a = nn.functional.relu(x_1a)\n",
    "        x_1b = self.conv1_s2(x)\n",
    "        x_1b = nn.functional.relu(x_1b)\n",
    "        \n",
    "        x = torch.concat([x_1a, x_1b],dim=1)\n",
    "        x_2a = self.conv2(x)\n",
    "        x_2a = nn.functional.relu(x_2a)\n",
    "        x_2b = self.conv2_s2(x)\n",
    "        x_2b = nn.functional.relu(x_2b)\n",
    "\n",
    "        x = torch.concat([x_2a, x_2b],dim=1)\n",
    "        x = self.conv3(x)\n",
    "        x = nn.functional.tanh(x)\n",
    "        x = rearrange(x, 'b 1 w h -> b w h')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "0d9eb43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = OthelloNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "e80a601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 6, 6])\n",
      "torch.Size([1, 40, 6, 6])\n",
      "torch.Size([1, 1, 6, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 6, 6])"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(rearrange(tensor_state, 'w h -> 1 1 w h'))[0,0]:shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "cf5efc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = nn.Sequential(\n",
    "    # block 1\n",
    "    nn.Conv2d(1,20, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout2d(p=0.1),\n",
    "    nn.BatchNorm2d(20),\n",
    "    \n",
    "    # block 2\n",
    "    nn.Conv2d(20,20, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout2d(p=0.1),\n",
    "    nn.BatchNorm2d(20),\n",
    "    \n",
    "    # block 3\n",
    "    nn.Conv2d(20,20, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout2d(p=0.1),\n",
    "    nn.BatchNorm2d(20),\n",
    "    \n",
    "    # compress channels to 1 and softmax\n",
    "    nn.Conv2d(20, 1, kernel_size=1),\n",
    "    Rearrange('b 1 w h -> b w h'),\n",
    "    nn.Tanh()\n",
    "#     nn.Softmax(dim = 1),\n",
    "#     Rearrange('b (w h) -> b w h', w = 6, h = 6)\n",
    ")\n",
    "batch_boards = torch.as_tensor([[state], [state]], dtype=torch.float32)\n",
    "# network.to(device)\n",
    "# assert network(batch_boards).sum(axis=1).sum(axis=1)[0] == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ed0bf040",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = network(torch.as_tensor([[state]], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f99a91cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4081,  0.3099,  0.3523, -0.2370,  0.1816,  0.1558],\n",
       "         [ 0.1065,  0.7942, -0.0668, -0.4197, -0.4196, -0.5736],\n",
       "         [-0.0603, -0.2125, -0.1890,  0.9293, -0.6834, -0.1090],\n",
       "         [ 0.0640,  0.8236, -0.7896,  0.9443,  0.3014, -0.3497],\n",
       "         [ 0.6135,  0.6385,  0.7154, -0.3351, -0.0139, -0.2774],\n",
       "         [ 0.1625,  0.5912, -0.0162,  0.3044, -0.0772,  0.0234]]],\n",
       "       grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "96a8eb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 4],\n",
       "       [4, 2],\n",
       "       [4, 4]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(possible_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "6165ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_values = preds[0][np.array(possible_moves).transpose()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "cd3064b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6834,  0.7154, -0.0139], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a827bc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  1., -1.,  0.,  0.],\n",
       "          [ 0.,  0., -1., -1.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., -1.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "        [[[ 1.,  1.,  1.,  1.,  1.,  1.],\n",
       "          [ 1.,  1.,  1.,  1.,  1.,  1.],\n",
       "          [ 1.,  1.,  2.,  0.,  1.,  1.],\n",
       "          [ 1.,  1.,  0.,  0.,  1.,  1.],\n",
       "          [ 1.,  1.,  1.,  0.,  1.,  1.],\n",
       "          [ 1.,  1.,  1.,  1.,  1.,  1.]]]])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_boards = torch.as_tensor([[state], [state+1]], dtype=torch.float32)\n",
    "batch_boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7b3fb1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3100,  0.5100,  0.0500,  0.0700, -0.0600,  0.1000],\n",
       "         [ 0.1300,  0.1200,  0.1000, -0.2700, -0.5500,  0.2300],\n",
       "         [ 0.1900, -0.5100,  0.0900,  0.1800, -0.1900, -0.2300],\n",
       "         [-0.4700,  0.5700,  0.0000,  0.6000, -0.0300, -0.8900],\n",
       "         [ 0.6200,  0.2700,  0.1000,  0.1000,  0.5800, -0.4500],\n",
       "         [-0.0100,  0.3300,  0.1700,  0.5200,  0.1900, -0.3000]],\n",
       "\n",
       "        [[ 0.6700,  0.3300, -0.1200, -0.0800, -0.1600,  0.3500],\n",
       "         [ 0.5200,  0.1900,  0.1700,  0.0200,  0.6500,  0.4000],\n",
       "         [-0.0900,  0.8800,  0.2500,  0.7200,  0.7700, -0.6500],\n",
       "         [ 0.0400,  0.5400,  0.1700,  0.8200, -0.1100, -0.4800],\n",
       "         [ 0.1900,  0.6800,  0.3100, -0.1300, -0.2400, -0.6900],\n",
       "         [ 0.3400,  0.2500, -0.0800,  0.7300,  0.5600, -0.0800]]],\n",
       "       grad_fn=<RoundBackward1>)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = network(batch_boards)\n",
    "preds.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "efaf5995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2],\n",
       "        [2, 2]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_moves = torch.as_tensor([(2,2), (2,2)], dtype=torch.long)\n",
    "batch_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "82c4f92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0943, 0.2469], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[range(preds.shape[0]),batch_moves[0], batch_moves[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "77e0883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_move(net, state, possible_moves):\n",
    "    if len(possible_moves) == 0: return None\n",
    "    preds = net(rearrange(torch.as_tensor(state), 'w h -> 1 1 w h'))\n",
    "    values = preds[0][np.array(possible_moves).transpose()]\n",
    "    return possible_moves[values.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b826281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameState:\n",
    "    def __init__(self, state, gamma=0.95, player='player', parent = None):\n",
    "        self.state = state\n",
    "        self.player = player\n",
    "        if parent_state: self.parent = parent\n",
    "        if parent_state: self.depth = parent.depth + 1\n",
    "        else: self.depth = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "25810cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(move_player, move_opponent, branching_factor = np.ones(36)):\n",
    "    state, reward, done, info = env.reset(verbose=True)\n",
    "    root = GameState(state)\n",
    "    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "848868b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 6, 6])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange(torch.as_tensor(state), 'w h -> 1 1 w h').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "29e7d655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 6, 6])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "cd3d9928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "1301f0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 2, 0, 4, 4, 0, 2, 4, 5, 0, 2, 2, 0, 3, 1, 2, 0, 0, 2, 5, 4, 4, 2, 1,\n",
       "        4, 5, 4, 5, 1, 5, 5, 1, 0, 3, 2, 1, 4, 3, 1, 3, 1, 2, 4, 1, 4, 2, 0, 0,\n",
       "        0, 1, 4, 3, 3, 4, 3, 4, 0, 5, 0, 1, 1, 0, 4, 5])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "1bf82a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 6, 6])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "2f7bb5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "state, reward, done, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5c4cb381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., -1.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., -1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "11fa3a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_state = torch.as_tensor(state, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c37a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_state.se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "5363537b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "08b47a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state1 = (tensor_state == 1).to(torch.float32)\n",
    "state0 = (tensor_state == 0).to(torch.float32)\n",
    "state_1 = (tensor_state == -1).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "12247902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1., -1., -1., -1., -1.],\n",
       "        [-1.,  0.,  0.,  0.,  0., -1.],\n",
       "        [-1.,  0.,  1.,  1.,  0., -1.],\n",
       "        [-1.,  0.,  1.,  1.,  0., -1.],\n",
       "        [-1.,  0.,  0.,  0.,  0., -1.],\n",
       "        [-1., -1., -1., -1., -1., -1.]])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyramid = torch.ones((2,2))\n",
    "pyramid = nn.functional.pad(pyramid, pad=(1,1,1,1),value=0)\n",
    "pyramid = nn.functional.pad(pyramid, pad=(1,1,1,1),value=-1)\n",
    "pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "bc93f1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 6])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([state1, state0, state_1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "b352a126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorify(np_state):\n",
    "    state = torch.as_tensor(state, dtype=torch.float32)\n",
    "    state1 = (tensor_state == 1).to(torch.float32)\n",
    "    state0 = (tensor_state == 0).to(torch.float32)\n",
    "    state_1 = (tensor_state == -1).to(torch.float32)\n",
    "    return torch.stack([state1,state0,state_1,pyramid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "47e07654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorify(np_state):\n",
    "    tensor_state = torch.as_tensor(np_state, dtype=torch.float32)\n",
    "    state1 = (tensor_state == 1).to(torch.float32)\n",
    "    state0 = (tensor_state == 0).to(torch.float32)\n",
    "    state_1 = (tensor_state == -1).to(torch.float32)\n",
    "    return torch.stack([state1,state0,state_1,pyramid])\n",
    "\n",
    "def greedy_move(net, state, possible_moves):\n",
    "    if len(possible_moves) == 0: return None\n",
    "    preds = net(rearrange(torch.as_tensor(state), 'c w h -> 1 c w h'))\n",
    "    values = preds[0][np.array(possible_moves).transpose()]\n",
    "    return possible_moves[values.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "e66080e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hristo\\AppData\\Local\\Temp\\ipykernel_18524\\123238664.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for episode in tqdm_notebook(range(10)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd351f978d7b4c6ebd36835ed2786211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "EinopsError",
     "evalue": " Error while processing rearrange-reduction pattern \"w h -> 1 1 w h\".\n Input tensor shape: torch.Size([4, 6, 6]). Additional info: {}.\n Expected 2 dimensions, got 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\einops\\einops.py:410\u001b[0m, in \u001b[0;36mreduce\u001b[1;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[0;32m    409\u001b[0m     recipe \u001b[38;5;241m=\u001b[39m _prepare_transformation_recipe(pattern, reduction, axes_lengths\u001b[38;5;241m=\u001b[39mhashable_axes_lengths)\n\u001b[1;32m--> 410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_recipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EinopsError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\einops\\einops.py:233\u001b[0m, in \u001b[0;36m_apply_recipe\u001b[1;34m(recipe, tensor, reduction_type)\u001b[0m\n\u001b[0;32m    231\u001b[0m backend \u001b[38;5;241m=\u001b[39m get_backend(tensor)\n\u001b[0;32m    232\u001b[0m init_shapes, reduced_axes, axes_reordering, added_axes, final_shapes \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m--> 233\u001b[0m     \u001b[43m_reconstruct_from_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m tensor \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mreshape(tensor, init_shapes)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\einops\\einops.py:163\u001b[0m, in \u001b[0;36m_reconstruct_from_shape_uncached\u001b[1;34m(self, shape)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_composite_axes):\n\u001b[1;32m--> 163\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_composite_axes), \u001b[38;5;28mlen\u001b[39m(shape)))\n\u001b[0;32m    165\u001b[0m ellipsis_shape: List[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mEinopsError\u001b[0m: Expected 2 dimensions, got 3",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [412]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     move \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(possible_moves)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 14\u001b[0m     move \u001b[38;5;241m=\u001b[39m \u001b[43mgreedy_move\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpossible_moves\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m state, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(move)\n\u001b[0;32m     16\u001b[0m tensor_state \u001b[38;5;241m=\u001b[39m tensorify(state)\n",
      "Input \u001b[1;32mIn [290]\u001b[0m, in \u001b[0;36mgreedy_move\u001b[1;34m(net, state, possible_moves)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgreedy_move\u001b[39m(net, state, possible_moves):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(possible_moves) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     preds \u001b[38;5;241m=\u001b[39m net(\u001b[43mrearrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw h -> 1 1 w h\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      4\u001b[0m     values \u001b[38;5;241m=\u001b[39m preds[\u001b[38;5;241m0\u001b[39m][np\u001b[38;5;241m.\u001b[39marray(possible_moves)\u001b[38;5;241m.\u001b[39mtranspose()]\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m possible_moves[values\u001b[38;5;241m.\u001b[39margmax()]\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\einops\\einops.py:487\u001b[0m, in \u001b[0;36mrearrange\u001b[1;34m(tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRearrange can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be applied to an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    486\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m get_backend(tensor[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstack_on_zeroth_dimension(tensor)\n\u001b[1;32m--> 487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reduce(tensor, pattern, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrearrange\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39maxes_lengths)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\einops\\einops.py:418\u001b[0m, in \u001b[0;36mreduce\u001b[1;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[0;32m    416\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Input is list. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    417\u001b[0m message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdditional info: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(axes_lengths)\n\u001b[1;32m--> 418\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(message \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e))\n",
      "\u001b[1;31mEinopsError\u001b[0m:  Error while processing rearrange-reduction pattern \"w h -> 1 1 w h\".\n Input tensor shape: torch.Size([4, 6, 6]). Additional info: {}.\n Expected 2 dimensions, got 3"
     ]
    }
   ],
   "source": [
    "for episode in tqdm_notebook(range(10)):\n",
    "    state, reward, done, info = env.reset()\n",
    "    tensor_state = tensorify(state) #torch.as_tensor(state, dtype=torch.float32)\n",
    "    memory_episode = []\n",
    "    while not done:\n",
    "        prev_state = tensor_state\n",
    "        possible_moves = get_legal_moves(state)\n",
    "        if len(possible_moves) == 0:\n",
    "            move = None\n",
    "\n",
    "        elif random.random() < epsilon:\n",
    "            move = random.choice(possible_moves)\n",
    "        else:\n",
    "            move = greedy_move(network, prev_state, possible_moves)\n",
    "        state, reward, done, info = env.step(move)\n",
    "        tensor_state = tensorify(state)\n",
    "        if move is not None:\n",
    "            memory_episode.append((prev_state, reward, move, tensor_state))\n",
    "\n",
    "        if len(memory) > N:\n",
    "            memory.pop(0)\n",
    "\n",
    "        if M < len(memory):\n",
    "\n",
    "            random_choices = np.random.choice(range(len(memory)), size=M, replace=False)\n",
    "\n",
    "            old_states = torch.stack([memory[idx][0] for idx in random_choices])\n",
    "            states = torch.stack([memory[idx][3] for idx in random_choices])\n",
    "            rewards = torch.tensor(np.array([memory[idx][1] for idx in random_choices]),\n",
    "                                    dtype=torch.float32)\n",
    "            moves = torch.as_tensor([memory[idx][2] for idx in random_choices], dtype=torch.long)\n",
    "            old_values = network(old_states)\n",
    "            old_value_moves = old_values[range(old_values.shape[0]),moves[:,0], moves[:,1]]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                new_values = network(states)\n",
    "                new_value_moves = new_values[range(new_values.shape[0]),moves[:,0], moves[:,1]]\n",
    "            loss = loss_fn(old_value_moves, rewards + gamma * new_value_moves)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(network.parameters(), 50.0)\n",
    "            optim.step()\n",
    "    num_steps = len(memory_episode)\n",
    "    for idx, step in enumerate(memory_episode):\n",
    "        discounted_reward = reward * gamma**(num_steps-idx)\n",
    "        memory_episode[idx] = (step[0], discounted_reward, step[2], step[3])\n",
    "    memory = memory + memory_episode\n",
    "\n",
    "    epsilon *= epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "147522e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hristo\\AppData\\Local\\Temp\\ipykernel_18524\\427645414.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for episode in tqdm_notebook(range(n_episodes)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526ae2e46d92443fa3a9e2591f3b7136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train():\n",
    "    n_episodes = 100\n",
    "    gamma = 0.9\n",
    "    epsilon = 0.3\n",
    "    epsilon_decay = 0.99\n",
    "    env = OthelloEnv()\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    optim = torch.optim.AdamW(network.parameters())\n",
    "    memory = []\n",
    "\n",
    "    N = 2000\n",
    "    M = 64\n",
    "\n",
    "    for episode in tqdm_notebook(range(n_episodes)):\n",
    "        state, reward, done, info = env.reset()\n",
    "        state = torch.as_tensor(state, dtype=torch.float32)\n",
    "\n",
    "        while not done:\n",
    "            prev_state = state\n",
    "    #             prev_state_value = V(prev_state)\n",
    "            possible_moves = get_legal_moves(state)\n",
    "            if len(possible_moves) == 0:\n",
    "                move = None\n",
    "\n",
    "            elif random.random() < epsilon:\n",
    "                move = random.choice(possible_moves)\n",
    "            else:\n",
    "                move = greedy_move(network, prev_state, possible_moves)\n",
    "            state, reward, done, info = env.step(move)\n",
    "            state = torch.as_tensor(state, dtype=torch.float32)\n",
    "            if move is not None:\n",
    "                memory.append((prev_state, reward, move, state))\n",
    "\n",
    "            if len(memory) > N:\n",
    "                memory.pop(0)\n",
    "\n",
    "            if M < len(memory):\n",
    "\n",
    "                random_choices = np.random.choice(range(len(memory)), size=M, replace=False)\n",
    "\n",
    "                old_states = torch.stack([memory[idx][0] for idx in random_choices])\n",
    "                old_states = rearrange(old_states, 'b w h -> b 1 w h')\n",
    "                states = torch.stack([memory[idx][3] for idx in random_choices])\n",
    "                states = rearrange(states, 'b w h -> b 1 w h')\n",
    "                rewards = torch.tensor(np.array([memory[idx][1] for idx in random_choices]),\n",
    "                                        dtype=torch.float32)\n",
    "                moves = torch.as_tensor([memory[idx][2] for idx in random_choices], dtype=torch.long)\n",
    "                old_values = network(old_states)\n",
    "                old_value_moves = old_values[range(old_values.shape[0]),moves[:,0], moves[:,1]]\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    new_values = network(states)\n",
    "                    new_value_moves = new_values[range(new_values.shape[0]),moves[:,0], moves[:,1]]\n",
    "                loss = loss_fn(old_value_moves, rewards + gamma * new_value_moves)\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "\n",
    "        epsilon *= epsilon_decay\n",
    "        \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "0463a329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22229219984074694"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.995**300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "77bb859b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hristo\\AppData\\Local\\Temp\\ipykernel_18524\\1234252956.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for _ in tqdm_notebook(range(1000)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab5f40fc0e54c1ab020ed98eb25ba1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [295]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m outcomes \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm_notebook(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m)):\n\u001b[1;32m---> 13\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[43mplay_othello_game\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43myour_choose_move\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchoose_move_no_value_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopponent_choose_move\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchoose_move_randomly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgame_speed_multiplier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000000000000000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     outcomes[reward] \u001b[38;5;241m=\u001b[39m outcomes\u001b[38;5;241m.\u001b[39mget(reward, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(outcomes)\n",
      "File \u001b[1;32m~\\Desktop\\hristo\\Documents\\Delta academy\\othello\\game_mechanics.py:66\u001b[0m, in \u001b[0;36mplay_othello_game\u001b[1;34m(your_choose_move, opponent_choose_move, game_speed_multiplier, render, verbose)\u001b[0m\n\u001b[0;32m     64\u001b[0m     state, reward, done, info \u001b[38;5;241m=\u001b[39m game\u001b[38;5;241m.\u001b[39mstep(action, verbose)\n\u001b[0;32m     65\u001b[0m     total_return \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m---> 66\u001b[0m     \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgame_speed_multiplier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_return\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def choose_move_no_value_fn(state: Any) -> Optional[Tuple[int, int]]:\n",
    "    \"\"\"The arguments in play_connect_4_game() require functions that only take the state as\n",
    "    input.\n",
    "\n",
    "    This converts choose_move() to that format.\n",
    "    \"\"\"\n",
    "    state = torch.as_tensor(state, dtype=torch.float32)\n",
    "    possible_moves = get_legal_moves(state)\n",
    "    return greedy_move(network, state, possible_moves)\n",
    "\n",
    "outcomes = {}\n",
    "for _ in tqdm_notebook(range(1000)):\n",
    "    reward = play_othello_game(\n",
    "        your_choose_move=choose_move_no_value_fn,\n",
    "        opponent_choose_move=choose_move_randomly,\n",
    "        game_speed_multiplier=10000000000000000,\n",
    "        verbose=False,\n",
    "    )\n",
    "    outcomes[reward] = outcomes.get(reward, 0) + 1\n",
    "    \n",
    "print(outcomes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
