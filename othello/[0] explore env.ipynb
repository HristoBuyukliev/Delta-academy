{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "8bd163f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from check_submission import check_submission\n",
    "from game_mechanics import (\n",
    "    OthelloEnv,\n",
    "    choose_move_randomly,\n",
    "    load_network,\n",
    "    play_othello_game,\n",
    "    save_network,\n",
    "    get_legal_moves\n",
    ")\n",
    "\n",
    "from einops.layers.torch import Rearrange\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm_notebook\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57d577d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting game. Player -1 has first move\n",
      " [['*' '*' '*' '*' '*' '*']\n",
      " ['*' '*' '*' '*' '*' '*']\n",
      " ['*' '*' 'X' 'O' '*' '*']\n",
      " ['*' '*' 'O' 'X' '*' '*']\n",
      " ['*' '*' '*' '*' '*' '*']\n",
      " ['*' '*' '*' '*' '*' '*']]\n",
      "\n",
      "Player -1 places counter at row 4, column 3\n",
      "[['*' '*' '*' '*' '*' '*']\n",
      " ['*' '*' '*' '*' '*' '*']\n",
      " ['*' '*' 'X' 'O' '*' '*']\n",
      " ['*' '*' 'O' 'O' '*' '*']\n",
      " ['*' '*' '*' 'O' '*' '*']\n",
      " ['*' '*' '*' '*' '*' '*']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = OthelloEnv()\n",
    "state, reward, done, info = env.reset(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "b7fb9e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OthelloNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OthelloNet, self).__init__()\n",
    "        hidden = 20 \n",
    "        # stride 1\n",
    "        self.conv1 = nn.Conv2d(1,hidden, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(hidden*2,hidden, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(hidden*2,1, kernel_size=1, padding=0)\n",
    "        \n",
    "        # stride 2\n",
    "        self.conv1_s2 = nn.Conv2d(1,hidden, kernel_size=3, padding=2,dilation=2)\n",
    "        self.conv2_s2 = nn.Conv2d(hidden*2,hidden, kernel_size=3, padding=2,dilation=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_1a = self.conv1(x)\n",
    "        x_1a = nn.functional.relu(x_1a)\n",
    "        x_1b = self.conv1_s2(x)\n",
    "        x_1b = nn.functional.relu(x_1b)\n",
    "        \n",
    "        x = torch.concat([x_1a, x_1b],dim=1)\n",
    "        x_2a = self.conv2(x)\n",
    "        x_2a = nn.functional.relu(x_2a)\n",
    "        x_2b = self.conv2_s2(x)\n",
    "        x_2b = nn.functional.relu(x_2b)\n",
    "\n",
    "        x = torch.concat([x_2a, x_2b],dim=1)\n",
    "        x = self.conv3(x)\n",
    "        x = nn.functional.tanh(x)\n",
    "        x = rearrange(x, 'b 1 w h -> b w h')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "e25d2971",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = OthelloNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "d90e48d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 6, 6])\n",
      "torch.Size([1, 40, 6, 6])\n",
      "torch.Size([1, 1, 6, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 6, 6])"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(rearrange(tensor_state, 'w h -> 1 1 w h'))[0,0]:shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "09241219",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OthelloNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OthelloNet, self).__init__()\n",
    "        hidden = 20 \n",
    "        # stride 1\n",
    "        self.conv1 = nn.Conv2d(4,hidden, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(hidden*2,hidden, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(hidden*2,1, kernel_size=1, padding=0)\n",
    "        \n",
    "        # stride 2\n",
    "        self.conv1_s2 = nn.Conv2d(4,hidden, kernel_size=3, padding=2,dilation=2)\n",
    "        self.conv2_s2 = nn.Conv2d(hidden*2,hidden, kernel_size=3, padding=2,dilation=2)\n",
    "    \n",
    "#         self.linear = nn.Linear(hidden*2*6*6, hidden)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_1a = self.conv1(x)\n",
    "        x_1a = nn.functional.relu(x_1a)\n",
    "        x_1b = self.conv1_s2(x)\n",
    "        x_1b = nn.functional.relu(x_1b)\n",
    "        \n",
    "        x = torch.concat([x_1a, x_1b],dim=1)\n",
    "        x_2a = self.conv2(x)\n",
    "        x_2a = nn.functional.relu(x_2a)\n",
    "        x_2b = self.conv2_s2(x)\n",
    "        x_2b = nn.functional.relu(x_2b)\n",
    "\n",
    "        x = torch.concat([x_2a, x_2b],dim=1)\n",
    "        # add a FC layer\n",
    "#         x_fc = rearrange(x, 'b c w h -> b (c w h)')\n",
    "#         x_fc = self.linear(x_fc)\n",
    "#         x_fc = repeat(x_fc, 'b c -> b c w h', w=6,h=6)\n",
    "#         x = torch.concat([x, x_fc], dim=1)\n",
    "        \n",
    "        # final flatten\n",
    "        x = self.conv3(x)\n",
    "        x = nn.functional.tanh(x)\n",
    "        x = rearrange(x, 'b 1 w h -> b w h')\n",
    "        return x\n",
    "    \n",
    "network = OthelloNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a0ce4c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = network(torch.as_tensor([[state]], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6c443370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4081,  0.3099,  0.3523, -0.2370,  0.1816,  0.1558],\n",
       "         [ 0.1065,  0.7942, -0.0668, -0.4197, -0.4196, -0.5736],\n",
       "         [-0.0603, -0.2125, -0.1890,  0.9293, -0.6834, -0.1090],\n",
       "         [ 0.0640,  0.8236, -0.7896,  0.9443,  0.3014, -0.3497],\n",
       "         [ 0.6135,  0.6385,  0.7154, -0.3351, -0.0139, -0.2774],\n",
       "         [ 0.1625,  0.5912, -0.0162,  0.3044, -0.0772,  0.0234]]],\n",
       "       grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e3091694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 4],\n",
       "       [4, 2],\n",
       "       [4, 4]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(possible_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0aea50bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_values = preds[0][np.array(possible_moves).transpose()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "074186e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6834,  0.7154, -0.0139], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "6a84dec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  1., -1.,  0.,  0.],\n",
       "          [ 0.,  0., -1., -1.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., -1.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "        [[[ 1.,  1.,  1.,  1.,  1.,  1.],\n",
       "          [ 1.,  1.,  1.,  1.,  1.,  1.],\n",
       "          [ 1.,  1.,  2.,  0.,  1.,  1.],\n",
       "          [ 1.,  1.,  0.,  0.,  1.,  1.],\n",
       "          [ 1.,  1.,  1.,  0.,  1.,  1.],\n",
       "          [ 1.,  1.,  1.,  1.,  1.,  1.]]]])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_boards = torch.as_tensor([[state], [state+1]], dtype=torch.float32)\n",
    "batch_boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "07d6607e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3100,  0.5100,  0.0500,  0.0700, -0.0600,  0.1000],\n",
       "         [ 0.1300,  0.1200,  0.1000, -0.2700, -0.5500,  0.2300],\n",
       "         [ 0.1900, -0.5100,  0.0900,  0.1800, -0.1900, -0.2300],\n",
       "         [-0.4700,  0.5700,  0.0000,  0.6000, -0.0300, -0.8900],\n",
       "         [ 0.6200,  0.2700,  0.1000,  0.1000,  0.5800, -0.4500],\n",
       "         [-0.0100,  0.3300,  0.1700,  0.5200,  0.1900, -0.3000]],\n",
       "\n",
       "        [[ 0.6700,  0.3300, -0.1200, -0.0800, -0.1600,  0.3500],\n",
       "         [ 0.5200,  0.1900,  0.1700,  0.0200,  0.6500,  0.4000],\n",
       "         [-0.0900,  0.8800,  0.2500,  0.7200,  0.7700, -0.6500],\n",
       "         [ 0.0400,  0.5400,  0.1700,  0.8200, -0.1100, -0.4800],\n",
       "         [ 0.1900,  0.6800,  0.3100, -0.1300, -0.2400, -0.6900],\n",
       "         [ 0.3400,  0.2500, -0.0800,  0.7300,  0.5600, -0.0800]]],\n",
       "       grad_fn=<RoundBackward1>)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = network(batch_boards)\n",
    "preds.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "295ed688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2],\n",
       "        [2, 2]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_moves = torch.as_tensor([(2,2), (2,2)], dtype=torch.long)\n",
    "batch_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "964d2b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0943, 0.2469], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[range(preds.shape[0]),batch_moves[0], batch_moves[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "b2ca4384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_move(net, state, possible_moves):\n",
    "    if len(possible_moves) == 0: return None\n",
    "    preds = net(rearrange(torch.as_tensor(state), 'w h -> 1 1 w h'))\n",
    "    values = preds[0][np.array(possible_moves).transpose()]\n",
    "    return possible_moves[values.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0ca1226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameState:\n",
    "    def __init__(self, state, gamma=0.95, player='player', parent = None):\n",
    "        self.state = state\n",
    "        self.player = player\n",
    "        if parent_state: self.parent = parent\n",
    "        if parent_state: self.depth = parent.depth + 1\n",
    "        else: self.depth = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ce8b691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(move_player, move_opponent, branching_factor = np.ones(36)):\n",
    "    state, reward, done, info = env.reset(verbose=True)\n",
    "    root = GameState(state)\n",
    "    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "875b04d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 6, 6])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange(torch.as_tensor(state), 'w h -> 1 1 w h').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e38a092b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 6, 6])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "eebe5a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "14cf693e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 2, 0, 4, 4, 0, 2, 4, 5, 0, 2, 2, 0, 3, 1, 2, 0, 0, 2, 5, 4, 4, 2, 1,\n",
       "        4, 5, 4, 5, 1, 5, 5, 1, 0, 3, 2, 1, 4, 3, 1, 3, 1, 2, 4, 1, 4, 2, 0, 0,\n",
       "        0, 1, 4, 3, 3, 4, 3, 4, 0, 5, 0, 1, 1, 0, 4, 5])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "aa3bc45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 6, 6])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "2c6c15d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "state, reward, done, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "9f700c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., -1.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., -1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b1bfc960",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_state = torch.as_tensor(state, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226dba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_state.se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "a01f861a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "0e0c587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state1 = (tensor_state == 1).to(torch.float32)\n",
    "state0 = (tensor_state == 0).to(torch.float32)\n",
    "state_1 = (tensor_state == -1).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "46c73f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1., -1., -1., -1., -1.],\n",
       "        [-1.,  0.,  0.,  0.,  0., -1.],\n",
       "        [-1.,  0.,  1.,  1.,  0., -1.],\n",
       "        [-1.,  0.,  1.,  1.,  0., -1.],\n",
       "        [-1.,  0.,  0.,  0.,  0., -1.],\n",
       "        [-1., -1., -1., -1., -1., -1.]])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyramid = torch.ones((2,2))\n",
    "pyramid = nn.functional.pad(pyramid, pad=(1,1,1,1),value=0)\n",
    "pyramid = nn.functional.pad(pyramid, pad=(1,1,1,1),value=-1)\n",
    "pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "ed9cf678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 6])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([state1, state0, state_1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "880519b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorify(np_state):\n",
    "    tensor_state = torch.as_tensor(np_state, dtype=torch.float32)\n",
    "    state1 = (tensor_state == 1).to(torch.float32)\n",
    "    state0 = (tensor_state == 0).to(torch.float32)\n",
    "    state_1 = (tensor_state == -1).to(torch.float32)\n",
    "    return torch.stack([state1,state0,state_1,pyramid])\n",
    "\n",
    "def greedy_move(net, state, possible_moves):\n",
    "    if len(possible_moves) == 0: return None\n",
    "    preds = net(rearrange(torch.as_tensor(state), 'c w h -> 1 c w h'))\n",
    "    values = preds[0][np.array(possible_moves).transpose()]\n",
    "    return possible_moves[values.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "095abc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hristo\\AppData\\Local\\Temp\\ipykernel_18524\\123238664.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for episode in tqdm_notebook(range(10)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9df0745667e4465a32ef10be3044624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hristo\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [6, 6] at entry 0 and [4, 6, 6] at entry 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [416]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m M \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(memory):\n\u001b[0;32m     25\u001b[0m     random_choices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(memory)), size\u001b[38;5;241m=\u001b[39mM, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 27\u001b[0m     old_states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrandom_choices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([memory[idx][\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m random_choices])\n\u001b[0;32m     29\u001b[0m     rewards \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray([memory[idx][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m random_choices]),\n\u001b[0;32m     30\u001b[0m                             dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [6, 6] at entry 0 and [4, 6, 6] at entry 2"
     ]
    }
   ],
   "source": [
    "for episode in tqdm_notebook(range(10)):\n",
    "    state, reward, done, info = env.reset()\n",
    "    tensor_state = tensorify(state) #torch.as_tensor(state, dtype=torch.float32)\n",
    "    memory_episode = []\n",
    "    while not done:\n",
    "        prev_state = tensor_state\n",
    "        possible_moves = get_legal_moves(state)\n",
    "        if len(possible_moves) == 0:\n",
    "            move = None\n",
    "\n",
    "        elif random.random() < epsilon:\n",
    "            move = random.choice(possible_moves)\n",
    "        else:\n",
    "            move = greedy_move(network, prev_state, possible_moves)\n",
    "        state, reward, done, info = env.step(move)\n",
    "        tensor_state = tensorify(state)\n",
    "        if move is not None:\n",
    "            memory_episode.append((prev_state, reward, move, tensor_state))\n",
    "\n",
    "        if len(memory) > N:\n",
    "            memory.pop(0)\n",
    "\n",
    "        if M < len(memory):\n",
    "\n",
    "            random_choices = np.random.choice(range(len(memory)), size=M, replace=False)\n",
    "\n",
    "            old_states = torch.stack([memory[idx][0] for idx in random_choices])\n",
    "            states = torch.stack([memory[idx][3] for idx in random_choices])\n",
    "            rewards = torch.tensor(np.array([memory[idx][1] for idx in random_choices]),\n",
    "                                    dtype=torch.float32)\n",
    "            moves = torch.as_tensor([memory[idx][2] for idx in random_choices], dtype=torch.long)\n",
    "            old_values = network(old_states)\n",
    "            old_value_moves = old_values[range(old_values.shape[0]),moves[:,0], moves[:,1]]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                new_values = network(states)\n",
    "                new_value_moves = new_values[range(new_values.shape[0]),moves[:,0], moves[:,1]]\n",
    "            loss = loss_fn(old_value_moves, rewards + gamma * new_value_moves)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(network.parameters(), 50.0)\n",
    "            optim.step()\n",
    "    num_steps = len(memory_episode)\n",
    "    for idx, step in enumerate(memory_episode):\n",
    "        discounted_reward = reward * gamma**(num_steps-idx)\n",
    "        memory_episode[idx] = (step[0], discounted_reward, step[2], step[3])\n",
    "    memory = memory + memory_episode\n",
    "\n",
    "    epsilon *= epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "2e5e260c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([6, 6]),\n",
       " torch.Size([6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6]),\n",
       " torch.Size([4, 6, 6])]"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[memory[idx][0].shape for idx in random_choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "a6f8f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Linear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "742f1e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = nn.Sequential(\n",
    "    nn.Linear(36, 36*3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "e50b0818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "d4579513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 108]           3,996\n",
      "================================================================\n",
      "Total params: 3,996\n",
      "Trainable params: 3,996\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(asd, input_size=(1,36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "ec0f8655",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [422]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m(asd)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "torch.summary(asd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "c434372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hristo\\AppData\\Local\\Temp\\ipykernel_18524\\427645414.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for episode in tqdm_notebook(range(n_episodes)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526ae2e46d92443fa3a9e2591f3b7136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train():\n",
    "    n_episodes = 100\n",
    "    gamma = 0.9\n",
    "    epsilon = 0.3\n",
    "    epsilon_decay = 0.99\n",
    "    env = OthelloEnv()\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    optim = torch.optim.AdamW(network.parameters())\n",
    "    memory = []\n",
    "\n",
    "    N = 2000\n",
    "    M = 64\n",
    "\n",
    "    for episode in tqdm_notebook(range(n_episodes)):\n",
    "        state, reward, done, info = env.reset()\n",
    "        state = torch.as_tensor(state, dtype=torch.float32)\n",
    "\n",
    "        while not done:\n",
    "            prev_state = state\n",
    "    #             prev_state_value = V(prev_state)\n",
    "            possible_moves = get_legal_moves(state)\n",
    "            if len(possible_moves) == 0:\n",
    "                move = None\n",
    "\n",
    "            elif random.random() < epsilon:\n",
    "                move = random.choice(possible_moves)\n",
    "            else:\n",
    "                move = greedy_move(network, prev_state, possible_moves)\n",
    "            state, reward, done, info = env.step(move)\n",
    "            state = torch.as_tensor(state, dtype=torch.float32)\n",
    "            if move is not None:\n",
    "                memory.append((prev_state, reward, move, state))\n",
    "\n",
    "            if len(memory) > N:\n",
    "                memory.pop(0)\n",
    "\n",
    "            if M < len(memory):\n",
    "\n",
    "                random_choices = np.random.choice(range(len(memory)), size=M, replace=False)\n",
    "\n",
    "                old_states = torch.stack([memory[idx][0] for idx in random_choices])\n",
    "                old_states = rearrange(old_states, 'b w h -> b 1 w h')\n",
    "                states = torch.stack([memory[idx][3] for idx in random_choices])\n",
    "                states = rearrange(states, 'b w h -> b 1 w h')\n",
    "                rewards = torch.tensor(np.array([memory[idx][1] for idx in random_choices]),\n",
    "                                        dtype=torch.float32)\n",
    "                moves = torch.as_tensor([memory[idx][2] for idx in random_choices], dtype=torch.long)\n",
    "                old_values = network(old_states)\n",
    "                old_value_moves = old_values[range(old_values.shape[0]),moves[:,0], moves[:,1]]\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    new_values = network(states)\n",
    "                    new_value_moves = new_values[range(new_values.shape[0]),moves[:,0], moves[:,1]]\n",
    "                loss = loss_fn(old_value_moves, rewards + gamma * new_value_moves)\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "\n",
    "        epsilon *= epsilon_decay\n",
    "        \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "6b5e08e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22229219984074694"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.995**300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "41eac73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hristo\\AppData\\Local\\Temp\\ipykernel_18524\\1234252956.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for _ in tqdm_notebook(range(1000)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab5f40fc0e54c1ab020ed98eb25ba1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [295]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m outcomes \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm_notebook(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m)):\n\u001b[1;32m---> 13\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[43mplay_othello_game\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43myour_choose_move\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchoose_move_no_value_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopponent_choose_move\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchoose_move_randomly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgame_speed_multiplier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000000000000000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     outcomes[reward] \u001b[38;5;241m=\u001b[39m outcomes\u001b[38;5;241m.\u001b[39mget(reward, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(outcomes)\n",
      "File \u001b[1;32m~\\Desktop\\hristo\\Documents\\Delta academy\\othello\\game_mechanics.py:66\u001b[0m, in \u001b[0;36mplay_othello_game\u001b[1;34m(your_choose_move, opponent_choose_move, game_speed_multiplier, render, verbose)\u001b[0m\n\u001b[0;32m     64\u001b[0m     state, reward, done, info \u001b[38;5;241m=\u001b[39m game\u001b[38;5;241m.\u001b[39mstep(action, verbose)\n\u001b[0;32m     65\u001b[0m     total_return \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m---> 66\u001b[0m     \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgame_speed_multiplier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_return\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def choose_move_no_value_fn(state: Any) -> Optional[Tuple[int, int]]:\n",
    "    \"\"\"The arguments in play_connect_4_game() require functions that only take the state as\n",
    "    input.\n",
    "\n",
    "    This converts choose_move() to that format.\n",
    "    \"\"\"\n",
    "    state = torch.as_tensor(state, dtype=torch.float32)\n",
    "    possible_moves = get_legal_moves(state)\n",
    "    return greedy_move(network, state, possible_moves)\n",
    "\n",
    "outcomes = {}\n",
    "for _ in tqdm_notebook(range(1000)):\n",
    "    reward = play_othello_game(\n",
    "        your_choose_move=choose_move_no_value_fn,\n",
    "        opponent_choose_move=choose_move_randomly,\n",
    "        game_speed_multiplier=10000000000000000,\n",
    "        verbose=False,\n",
    "    )\n",
    "    outcomes[reward] = outcomes.get(reward, 0) + 1\n",
    "    \n",
    "print(outcomes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
