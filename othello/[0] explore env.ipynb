{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d20685b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from check_submission import check_submission\n",
    "from game_mechanics import (\n",
    "    OthelloEnv,\n",
    "    choose_move_randomly,\n",
    "    load_network,\n",
    "    play_othello_game,\n",
    "    save_network,\n",
    "    get_legal_moves\n",
    ")\n",
    "\n",
    "from einops.layers.torch import Rearrange\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm_notebook\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fd031d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting game. Player -1 has first move\n",
      " [['*' '*' '*' '*' '*' '*']\n",
      " ['*' '*' '*' '*' '*' '*']\n",
      " ['*' '*' 'X' 'O' '*' '*']\n",
      " ['*' '*' 'O' 'X' '*' '*']\n",
      " ['*' '*' '*' '*' '*' '*']\n",
      " ['*' '*' '*' '*' '*' '*']]\n",
      "\n",
      "Player -1 places counter at row 4, column 3\n",
      "[['*' '*' '*' '*' '*' '*']\n",
      " ['*' '*' '*' '*' '*' '*']\n",
      " ['*' '*' 'X' 'O' '*' '*']\n",
      " ['*' '*' 'O' 'O' '*' '*']\n",
      " ['*' '*' '*' 'O' '*' '*']\n",
      " ['*' '*' '*' '*' '*' '*']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = OthelloEnv()\n",
    "state, reward, done, info = env.reset(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "b53105e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OthelloNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OthelloNet, self).__init__()\n",
    "        hidden = 20 \n",
    "        # stride 1\n",
    "        self.conv1 = nn.Conv2d(1,hidden, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(hidden*2,hidden, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(hidden*2,1, kernel_size=1, padding=0)\n",
    "        \n",
    "        # stride 2\n",
    "        self.conv1_s2 = nn.Conv2d(1,hidden, kernel_size=3, padding=2,dilation=2)\n",
    "        self.conv2_s2 = nn.Conv2d(hidden*2,hidden, kernel_size=3, padding=2,dilation=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_1a = self.conv1(x)\n",
    "        x_1a = nn.functional.relu(x_1a)\n",
    "        x_1b = self.conv1_s2(x)\n",
    "        x_1b = nn.functional.relu(x_1b)\n",
    "        \n",
    "        x = torch.concat([x_1a, x_1b],dim=1)\n",
    "        x_2a = self.conv2(x)\n",
    "        x_2a = nn.functional.relu(x_2a)\n",
    "        x_2b = self.conv2_s2(x)\n",
    "        x_2b = nn.functional.relu(x_2b)\n",
    "\n",
    "        x = torch.concat([x_2a, x_2b],dim=1)\n",
    "        x = self.conv3(x)\n",
    "        x = nn.functional.tanh(x)\n",
    "        x = rearrange(x, 'b 1 w h -> b w h')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "7b235f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = OthelloNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "4b3d8f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 6, 6])\n",
      "torch.Size([1, 40, 6, 6])\n",
      "torch.Size([1, 1, 6, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 6, 6])"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(rearrange(tensor_state, 'w h -> 1 1 w h'))[0,0]:shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6d6af9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = nn.Sequential(\n",
    "    # block 1\n",
    "    nn.Conv2d(1,20, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout2d(p=0.1),\n",
    "    nn.BatchNorm2d(20),\n",
    "    \n",
    "    # block 2\n",
    "    nn.Conv2d(20,20, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout2d(p=0.1),\n",
    "    nn.BatchNorm2d(20),\n",
    "    \n",
    "    # block 3\n",
    "    nn.Conv2d(20,20, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout2d(p=0.1),\n",
    "    nn.BatchNorm2d(20),\n",
    "    \n",
    "    # compress channels to 1 and softmax\n",
    "    nn.Conv2d(20, 1, kernel_size=1),\n",
    "    Rearrange('b 1 w h -> b w h'),\n",
    "    nn.Tanh()\n",
    "#     nn.Softmax(dim = 1),\n",
    "#     Rearrange('b (w h) -> b w h', w = 6, h = 6)\n",
    ")\n",
    "batch_boards = torch.as_tensor([[state], [state]], dtype=torch.float32)\n",
    "# network.to(device)\n",
    "# assert network(batch_boards).sum(axis=1).sum(axis=1)[0] == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "7165396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = network(torch.as_tensor([[state]], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "70b239b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4081,  0.3099,  0.3523, -0.2370,  0.1816,  0.1558],\n",
       "         [ 0.1065,  0.7942, -0.0668, -0.4197, -0.4196, -0.5736],\n",
       "         [-0.0603, -0.2125, -0.1890,  0.9293, -0.6834, -0.1090],\n",
       "         [ 0.0640,  0.8236, -0.7896,  0.9443,  0.3014, -0.3497],\n",
       "         [ 0.6135,  0.6385,  0.7154, -0.3351, -0.0139, -0.2774],\n",
       "         [ 0.1625,  0.5912, -0.0162,  0.3044, -0.0772,  0.0234]]],\n",
       "       grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8917111d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 4],\n",
       "       [4, 2],\n",
       "       [4, 4]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(possible_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a65c80aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_values = preds[0][np.array(possible_moves).transpose()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "af8825e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6834,  0.7154, -0.0139], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "5eb0fc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  1., -1.,  0.,  0.],\n",
       "          [ 0.,  0., -1., -1.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., -1.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "        [[[ 1.,  1.,  1.,  1.,  1.,  1.],\n",
       "          [ 1.,  1.,  1.,  1.,  1.,  1.],\n",
       "          [ 1.,  1.,  2.,  0.,  1.,  1.],\n",
       "          [ 1.,  1.,  0.,  0.,  1.,  1.],\n",
       "          [ 1.,  1.,  1.,  0.,  1.,  1.],\n",
       "          [ 1.,  1.,  1.,  1.,  1.,  1.]]]])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_boards = torch.as_tensor([[state], [state+1]], dtype=torch.float32)\n",
    "batch_boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "89306b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3100,  0.5100,  0.0500,  0.0700, -0.0600,  0.1000],\n",
       "         [ 0.1300,  0.1200,  0.1000, -0.2700, -0.5500,  0.2300],\n",
       "         [ 0.1900, -0.5100,  0.0900,  0.1800, -0.1900, -0.2300],\n",
       "         [-0.4700,  0.5700,  0.0000,  0.6000, -0.0300, -0.8900],\n",
       "         [ 0.6200,  0.2700,  0.1000,  0.1000,  0.5800, -0.4500],\n",
       "         [-0.0100,  0.3300,  0.1700,  0.5200,  0.1900, -0.3000]],\n",
       "\n",
       "        [[ 0.6700,  0.3300, -0.1200, -0.0800, -0.1600,  0.3500],\n",
       "         [ 0.5200,  0.1900,  0.1700,  0.0200,  0.6500,  0.4000],\n",
       "         [-0.0900,  0.8800,  0.2500,  0.7200,  0.7700, -0.6500],\n",
       "         [ 0.0400,  0.5400,  0.1700,  0.8200, -0.1100, -0.4800],\n",
       "         [ 0.1900,  0.6800,  0.3100, -0.1300, -0.2400, -0.6900],\n",
       "         [ 0.3400,  0.2500, -0.0800,  0.7300,  0.5600, -0.0800]]],\n",
       "       grad_fn=<RoundBackward1>)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = network(batch_boards)\n",
    "preds.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "680c2e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2],\n",
       "        [2, 2]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_moves = torch.as_tensor([(2,2), (2,2)], dtype=torch.long)\n",
    "batch_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c8c1a48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0943, 0.2469], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[range(preds.shape[0]),batch_moves[0], batch_moves[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "cdc4e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_move(net, state, possible_moves):\n",
    "    if len(possible_moves) == 0: return None\n",
    "    preds = net(rearrange(torch.as_tensor(state), 'w h -> 1 1 w h'))\n",
    "    values = preds[0][np.array(possible_moves).transpose()]\n",
    "    return possible_moves[values.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "fdc41111",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameState:\n",
    "    def __init__(self, state, gamma=0.95, player='player', parent = None):\n",
    "        self.state = state\n",
    "        self.player = player\n",
    "        if parent_state: self.parent = parent\n",
    "        if parent_state: self.depth = parent.depth + 1\n",
    "        else: self.depth = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1a23087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(move_player, move_opponent, branching_factor = np.ones(36)):\n",
    "    state, reward, done, info = env.reset(verbose=True)\n",
    "    root = GameState(state)\n",
    "    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "cb54c61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 6, 6])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange(torch.as_tensor(state), 'w h -> 1 1 w h').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "bbe0ba72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 6, 6])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d448332a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "4c9cb9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 2, 0, 4, 4, 0, 2, 4, 5, 0, 2, 2, 0, 3, 1, 2, 0, 0, 2, 5, 4, 4, 2, 1,\n",
       "        4, 5, 4, 5, 1, 5, 5, 1, 0, 3, 2, 1, 4, 3, 1, 3, 1, 2, 4, 1, 4, 2, 0, 0,\n",
       "        0, 1, 4, 3, 3, 4, 3, 4, 0, 5, 0, 1, 1, 0, 4, 5])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "dedcf0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 6, 6])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "478fe437",
   "metadata": {},
   "outputs": [],
   "source": [
    "state, reward, done, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "51a68609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., -1.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., -1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "86584463",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_state = torch.as_tensor(state, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88fbd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_state.se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "c4050376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "a052653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state1 = (tensor_state == 1).to(torch.float32)\n",
    "state0 = (tensor_state == 0).to(torch.float32)\n",
    "state_1 = (tensor_state == -1).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "5504e31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1., -1., -1., -1., -1.],\n",
       "        [-1.,  0.,  0.,  0.,  0., -1.],\n",
       "        [-1.,  0.,  1.,  1.,  0., -1.],\n",
       "        [-1.,  0.,  1.,  1.,  0., -1.],\n",
       "        [-1.,  0.,  0.,  0.,  0., -1.],\n",
       "        [-1., -1., -1., -1., -1., -1.]])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyramid = torch.ones((2,2))\n",
    "pyramid = nn.functional.pad(pyramid, pad=(1,1,1,1),value=0)\n",
    "pyramid = nn.functional.pad(pyramid, pad=(1,1,1,1),value=-1)\n",
    "pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "5810f9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 6])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([state1, state0, state_1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "ba60de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorify(np_state):\n",
    "    state = torch.as_tensor(state, dtype=torch.float32)\n",
    "    state1 = (tensor_state == 1).to(torch.float32)\n",
    "    state0 = (tensor_state == 0).to(torch.float32)\n",
    "    state_1 = (tensor_state == -1).to(torch.float32)\n",
    "    return torch.stack([state1,state0,state_1,pyramid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "0f4c57eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hristo\\AppData\\Local\\Temp\\ipykernel_18524\\427645414.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for episode in tqdm_notebook(range(n_episodes)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526ae2e46d92443fa3a9e2591f3b7136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train():\n",
    "    n_episodes = 100\n",
    "    gamma = 0.9\n",
    "    epsilon = 0.3\n",
    "    epsilon_decay = 0.99\n",
    "    env = OthelloEnv()\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    optim = torch.optim.AdamW(network.parameters())\n",
    "    memory = []\n",
    "\n",
    "    N = 2000\n",
    "    M = 64\n",
    "\n",
    "    for episode in tqdm_notebook(range(n_episodes)):\n",
    "        state, reward, done, info = env.reset()\n",
    "        state = torch.as_tensor(state, dtype=torch.float32)\n",
    "\n",
    "        while not done:\n",
    "            prev_state = state\n",
    "    #             prev_state_value = V(prev_state)\n",
    "            possible_moves = get_legal_moves(state)\n",
    "            if len(possible_moves) == 0:\n",
    "                move = None\n",
    "\n",
    "            elif random.random() < epsilon:\n",
    "                move = random.choice(possible_moves)\n",
    "            else:\n",
    "                move = greedy_move(network, prev_state, possible_moves)\n",
    "            state, reward, done, info = env.step(move)\n",
    "            state = torch.as_tensor(state, dtype=torch.float32)\n",
    "            if move is not None:\n",
    "                memory.append((prev_state, reward, move, state))\n",
    "\n",
    "            if len(memory) > N:\n",
    "                memory.pop(0)\n",
    "\n",
    "            if M < len(memory):\n",
    "\n",
    "                random_choices = np.random.choice(range(len(memory)), size=M, replace=False)\n",
    "\n",
    "                old_states = torch.stack([memory[idx][0] for idx in random_choices])\n",
    "                old_states = rearrange(old_states, 'b w h -> b 1 w h')\n",
    "                states = torch.stack([memory[idx][3] for idx in random_choices])\n",
    "                states = rearrange(states, 'b w h -> b 1 w h')\n",
    "                rewards = torch.tensor(np.array([memory[idx][1] for idx in random_choices]),\n",
    "                                        dtype=torch.float32)\n",
    "                moves = torch.as_tensor([memory[idx][2] for idx in random_choices], dtype=torch.long)\n",
    "                old_values = network(old_states)\n",
    "                old_value_moves = old_values[range(old_values.shape[0]),moves[:,0], moves[:,1]]\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    new_values = network(states)\n",
    "                    new_value_moves = new_values[range(new_values.shape[0]),moves[:,0], moves[:,1]]\n",
    "                loss = loss_fn(old_value_moves, rewards + gamma * new_value_moves)\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "\n",
    "        epsilon *= epsilon_decay\n",
    "        \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "58038dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22229219984074694"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.995**300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "85162247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hristo\\AppData\\Local\\Temp\\ipykernel_18524\\1234252956.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for _ in tqdm_notebook(range(1000)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab5f40fc0e54c1ab020ed98eb25ba1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [295]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m outcomes \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm_notebook(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m)):\n\u001b[1;32m---> 13\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[43mplay_othello_game\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43myour_choose_move\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchoose_move_no_value_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopponent_choose_move\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchoose_move_randomly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgame_speed_multiplier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000000000000000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     outcomes[reward] \u001b[38;5;241m=\u001b[39m outcomes\u001b[38;5;241m.\u001b[39mget(reward, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(outcomes)\n",
      "File \u001b[1;32m~\\Desktop\\hristo\\Documents\\Delta academy\\othello\\game_mechanics.py:66\u001b[0m, in \u001b[0;36mplay_othello_game\u001b[1;34m(your_choose_move, opponent_choose_move, game_speed_multiplier, render, verbose)\u001b[0m\n\u001b[0;32m     64\u001b[0m     state, reward, done, info \u001b[38;5;241m=\u001b[39m game\u001b[38;5;241m.\u001b[39mstep(action, verbose)\n\u001b[0;32m     65\u001b[0m     total_return \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m---> 66\u001b[0m     \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgame_speed_multiplier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_return\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def choose_move_no_value_fn(state: Any) -> Optional[Tuple[int, int]]:\n",
    "    \"\"\"The arguments in play_connect_4_game() require functions that only take the state as\n",
    "    input.\n",
    "\n",
    "    This converts choose_move() to that format.\n",
    "    \"\"\"\n",
    "    state = torch.as_tensor(state, dtype=torch.float32)\n",
    "    possible_moves = get_legal_moves(state)\n",
    "    return greedy_move(network, state, possible_moves)\n",
    "\n",
    "outcomes = {}\n",
    "for _ in tqdm_notebook(range(1000)):\n",
    "    reward = play_othello_game(\n",
    "        your_choose_move=choose_move_no_value_fn,\n",
    "        opponent_choose_move=choose_move_randomly,\n",
    "        game_speed_multiplier=10000000000000000,\n",
    "        verbose=False,\n",
    "    )\n",
    "    outcomes[reward] = outcomes.get(reward, 0) + 1\n",
    "    \n",
    "print(outcomes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
